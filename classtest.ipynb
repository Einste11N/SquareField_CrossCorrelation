{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tc\n",
    "tc.set_default_dtype(tc.float64)\n",
    "# tc.set_default_tensor_type(tc.DoubleTensor)\n",
    "\n",
    "import numpy as np\n",
    "import scipy.constants as sc\n",
    "from scipy.interpolate import interp1d\n",
    "import camb\n",
    "from copy import deepcopy\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cl_kSZ2_HI2_test():\n",
    "\n",
    "    def __init__(self, z_array, Tb = 1.8e-4, H0 = 67.75, ombh2 = 0.022):\n",
    "        \n",
    "        ##################################################s\n",
    "        # Define the cosmological parameters\n",
    "        params = camb.CAMBparams()\n",
    "        params.set_cosmology(H0=H0, ombh2=ombh2)\n",
    "        params.set_matter_power(redshifts = z_array, kmax=10, nonlinear=True)\n",
    "        results = camb.get_results(params)\n",
    "        backgrounds = camb.get_background(params)\n",
    "\n",
    "        # Calculate the background evolution and results\n",
    "        kh, z, Pm = results.get_matter_power_spectrum(minkh=1e-4, maxkh=10, npoints = 500, var1='delta_tot', var2='delta_tot')\n",
    "        Xe_of_z = np.array(backgrounds.get_background_redshift_evolution(z_array, ['x_e'], format='array')).flatten()\n",
    "        chi_of_z = np.array(results.comoving_radial_distance(z_array))\n",
    "\n",
    "        ##################################################\n",
    "        # Store the variables that we are interested in\n",
    "\n",
    "        # Constant scalars and arrays\n",
    "        self.TCMB = params.TCMB     # CMB temperature 2.7K\n",
    "        self.Tb = Tb                # HI brightness temperature, in unite mK\n",
    "        self.kh_array = kh          # Total kh array that we are interested in\n",
    "        self.z_list = z             # Total redshift array that we are interested in\n",
    "        \n",
    "        # Adjust order for interpolations\n",
    "        if len(z)<=5 : itp_order = 'linear'\n",
    "        else: itp_order = 'cubic'\n",
    "\n",
    "        # Interpolation functions of z\n",
    "        self.H_of_z = backgrounds.hubble_parameter                  # Hubble parameter, in unit \n",
    "        self.f_of_z = self.Growth_Rate_of_z(backgrounds, itp_order) # Logarithmic growth rate\n",
    "        self.Xe = interp1d(z_array, Xe_of_z, kind = itp_order)      # Ionized franction Xe\n",
    "        self.chi = interp1d(z_array, chi_of_z, kind = itp_order)    # Comoving distance chi\n",
    "\n",
    "        # interpolation functions of k and z\n",
    "        self.Pm = Pm # interp2d_tc(kh, z, Pm)             # Matter power spectrum\n",
    "\n",
    "        # save the cosmological model, for checking the result\n",
    "        self.results = results\n",
    "        self.BGEvolution = backgrounds\n",
    "        \n",
    "    def Growth_Rate_of_z(self, backgrounds, itp_order):\n",
    "        '''\n",
    "        Get the interpolation function for logarithmic growth rate f, \n",
    "        defined as f:=d(ln D)/d(ln a)\n",
    "        '''\n",
    "        # Since the growth rate almost does not vary with momentum scale, we fix kh=0.01 to get f\n",
    "        f_of_z = backgrounds.get_redshift_evolution([0.01], self.z_list, ['growth'])\n",
    "        return interp1d(self.z_list, np.array(f_of_z).flatten(), kind = itp_order)\n",
    "\n",
    "    def Pm_interpolation(self, x, y, Mode='bilinear'):\n",
    "        return interp2d_torch(tc.tensor(self.kh_array), tc.tensor(self.z_list), tc.tensor(self.Pm), x, y, mode=Mode)\n",
    "\n",
    "\n",
    "    def dCl(self, z, l, l1, l_min = 1, l_max = 1000, N_l = 1000, N_theta = 81):\n",
    "        \"\"\"Evaluare the integrand, dCl, as a function of z, l and l_1.\n",
    "\n",
    "        Here we sum over theta_1, l_2, and theta_2. To get the final C_l result, one has to integrate dCl over chi and l_1, for a given l.\n",
    "\n",
    "        Input\n",
    "        -----\n",
    "        `z` : float. \n",
    "            The redshift. \n",
    "\n",
    "        `l` : float. \n",
    "            The moment for C_l. Don't need to be an integer since we are in flat-sky approximation.\n",
    "\n",
    "        `l1` : float.\n",
    "            The norm of \\\\vec{l}_1.\n",
    "\n",
    "        \"\"\"\n",
    "        ##################################################\n",
    "        # Redefine the inputs as tc.tensors\n",
    "        z = tc.tensor([z], dtype=tc.float64)\n",
    "        l = tc.tensor([l], dtype=tc.float64)\n",
    "        l1 = tc.tensor([l1], dtype=tc.float64)\n",
    "\n",
    "        # # Make the mesh grid for theta_1, |l_2|, and theta_2\n",
    "        # t1_list = tc.arange(N_theta, dtype=tc.float64) * tc.pi / N_theta\n",
    "        # t2_list = deepcopy(t1_list)\n",
    "        # l2_list = tc.linspace(l_min, l_max, N_l, dtype=tc.float64)\n",
    "        # l2, t1, t2 = tc.meshgrid(l2_list, t1_list, t2_list, indexing='ij')\n",
    "\n",
    "        # Make the mesh grid for theta_1, |l_2|, and theta_2\n",
    "        t1 = tc.tensor([tc.pi / 3.], dtype=tc.float64)\n",
    "        t2_list = tc.arange(N_theta, dtype=tc.float64) * 2 * tc.pi / N_theta\n",
    "        l2_list = tc.linspace(l_min, l_max, N_l, dtype=tc.float64) # 10**tc.linspace(np.log10(l_min), np.log10(l_max), N_l, dtype=tc.float64)\n",
    "        l2, t2 = tc.meshgrid(l2_list, t2_list, indexing='ij')\n",
    "\n",
    "        # Pre-define useful varibales and constants\n",
    "        lsquare = l**2\n",
    "        l1square = l1**2\n",
    "        l2square = l2**2\n",
    "\n",
    "        l_dot_l1 = Polar_dot(l, 0., l1, t1)\n",
    "        l_dot_l2 = Polar_dot(l, 0., l2, t2)\n",
    "        l1_dot_l2 = Polar_dot(l1, t1, l2, t2)\n",
    "\n",
    "        l_m_l1_norm = tc.sqrt( lsquare + l1square - 2*l_dot_l1 )\n",
    "        l_p_l2_norm = tc.sqrt( lsquare + l2square + 2*l_dot_l2 )\n",
    "        l1_p_l2_norm = tc.sqrt( l1square + l2square + 2*l1_dot_l2 )\n",
    "        l_m_l1_p_l2_norm = tc.sqrt( lsquare + l1square + l2square - 2*l_dot_l1 + 2*l_dot_l2 - 2*l1_dot_l2 )\n",
    "\n",
    "        theta_l_p_l2 = Evaluate_angle(2, l, tc.tensor([0.]), l2, t2)\n",
    "        theta_l1_p_l2 = Evaluate_angle(2, l, tc.tensor([0.]), l2, t2)\n",
    "        theta_l_m_l1_p_l2 = Evaluate_angle(3, l, tc.tensor([0.]), -l1, t1, l2, t2)\n",
    "\n",
    "\n",
    "        Z_MEAN = 0.45 # mean redshift for HI observation\n",
    "        FREQ_HI = 1420. # in unit MHz\n",
    "        SIGMA_HI = 0.0115 * 1000. * (1. + Z_MEAN) / FREQ_HI\n",
    "        SIGMA_KSZ = deepcopy(SIGMA_HI)\n",
    "\n",
    "        ##################################################\n",
    "        # Evaluate the integrand\n",
    "        # Initialization\n",
    "        dCl_tot = tc.zeros_like(t2)\n",
    "\n",
    "        # Contribution originate from each term in Wick Theorem\n",
    "        # Term 5 \n",
    "        dCl = - tc.cos(theta_l1_p_l2 - t2) # - (l_dot_l2 + l2square) / l_p_l2_norm / l2\n",
    "        dCl *= self.Cross_Power(z, l1_p_l2_norm, 'e', 'e')\n",
    "        dCl *= self.Cross_Power(z, l_p_l2_norm, 'v', 'HI')\n",
    "        dCl *= self.Cross_Power(z, l2, 'v', 'HI')\n",
    "        dCl_tot += dCl\n",
    "        # Term 6 \n",
    "        dCl = - tc.cos(theta_l1_p_l2 - t2) # - (l_dot_l2 + l2square) / l_p_l2_norm / l2\n",
    "        dCl *= self.Cross_Power(z, l_m_l1_p_l2_norm, 'e', 'e')\n",
    "        dCl *= self.Cross_Power(z, l_p_l2_norm, 'v', 'HI')\n",
    "        dCl *= self.Cross_Power(z, l2, 'v', 'HI')\n",
    "        dCl_tot += dCl\n",
    "        # Term 8 \n",
    "        dCl = tc.cos(theta_l_p_l2 - theta_l1_p_l2) # (l_dot_l1 + l_dot_l2 + l1_dot_l2 + l2square) / l_p_l2_norm / l1_p_l2_norm\n",
    "        dCl *= self.Cross_Power(z, l_m_l1_p_l2_norm, 'e', 'v')\n",
    "        dCl *= self.Cross_Power(z, l_p_l2_norm, 'e', 'HI')\n",
    "        dCl *= self.Cross_Power(z, l2, 'v', 'HI')\n",
    "        dCl_tot += dCl\n",
    "        # Term 9\n",
    "        dCl = tc.cos(theta_l_m_l1_p_l2 - t2) # (l_dot_l2 - l1_dot_l2 + l2square) / l_m_l1_p_l2_norm / l2\n",
    "        dCl *= self.Cross_Power(z, l1_p_l2_norm, 'e', 'v')\n",
    "        dCl *= self.Cross_Power(z, l2, 'e', 'HI')\n",
    "        dCl *= self.Cross_Power(z, l_p_l2_norm, 'v', 'HI')\n",
    "        dCl_tot += dCl\n",
    "        # Term 10\n",
    "        dCl = tc.cos(theta_l1_p_l2 - t2)# (l1_dot_l2 + l2square) / l1_p_l2_norm / l2\n",
    "        dCl *= self.Cross_Power(z, l_p_l2_norm, 'e', 'HI')\n",
    "        dCl *= self.Cross_Power(z, l1_p_l2_norm, 'e', 'v')\n",
    "        dCl *= self.Cross_Power(z, l2, 'v', 'HI')\n",
    "        dCl_tot += dCl\n",
    "        # Term 11\n",
    "        dCl = -1.\n",
    "        dCl *= self.Cross_Power(z, l_p_l2_norm, 'e', 'HI')\n",
    "        dCl *= self.Cross_Power(z, l1_p_l2_norm, 'v', 'v')\n",
    "        dCl *= self.Cross_Power(z, l2, 'e', 'HI')\n",
    "        dCl_tot += dCl\n",
    "        # Term 13\n",
    "        dCl = tc.cos(theta_l_m_l1_p_l2 - theta_l_p_l2) # (lsquare + l2square + 2*l_dot_l2 - l_dot_l1 - l1_dot_l2) / l_p_l2_norm / l_m_l1_p_l2_norm\n",
    "        dCl *= self.Cross_Power(z, l2, 'e', 'HI')\n",
    "        dCl *= self.Cross_Power(z, l_m_l1_p_l2_norm, 'e', 'v')\n",
    "        dCl *= self.Cross_Power(z, l1_p_l2_norm, 'v', 'HI')\n",
    "        dCl_tot += dCl\n",
    "        # Term 14\n",
    "        dCl = -1.\n",
    "        dCl = self.Cross_Power(z, l2, 'e', 'HI')\n",
    "        dCl *= self.Cross_Power(z, l_m_l1_p_l2_norm, 'v', 'v')\n",
    "        dCl *= self.Cross_Power(z, l1_p_l2_norm, 'e', 'HI')\n",
    "        dCl_tot += dCl\n",
    "\n",
    "        dCl_terms = dCl_tot.clone().detach()\n",
    "\n",
    "        # The beam functions\n",
    "        dCl_tot *= self.Beam_kSZ(l_m_l1_norm, SIGMA_KSZ) * self.Beam_kSZ(l1, SIGMA_KSZ) * self.Beam_HI(l_p_l2_norm, SIGMA_HI) * self.Beam_HI(l2, SIGMA_HI)\n",
    "        # The window functions and the metric determinant contribution \n",
    "        dCl_tot *= l1 * l2 * self.F_kSZ(z)**2 * self.G_HI(z)**2 * self.dchi_by_dz(z)\n",
    "\n",
    "        dCl_res = tc.sum(dCl_tot) * t2_list[1] * (l_max - l_min) / (N_l - 1)\n",
    "\n",
    "        return l2, t2, dCl_res, dCl_tot, dCl_terms\n",
    "    \n",
    "\n",
    "    def dchi_by_dz(self, z):\n",
    "        return sc.c / self.H_of_z(z)\n",
    "\n",
    "    def F_kSZ(self, z):\n",
    "        return tc.tensor(self.Xe(z)) * (1+z)**2 / tc.tensor(self.chi(z))**2\n",
    "    \n",
    "    def G_HI(self, z):\n",
    "        return 1 / (self.z_list[-1] - self.z_list[0]) / self.chi(z)**2\n",
    "\n",
    "    def Beam_kSZ(self, l, singma_kSZ):\n",
    "        return tc.exp(-l**2 * singma_kSZ**2 / 2)\n",
    "    \n",
    "    def Beam_HI(self, l, singma_HI):\n",
    "        return tc.exp(-l**2 * singma_HI**2 / 2)\n",
    "\n",
    "    def Cross_Power(self, z, L, b1, b2, cut_off= tc.tensor([2.])):\n",
    "        \n",
    "        chi = self.chi(z)\n",
    "        kh = L / chi\n",
    "        kh_cutoff = cut_off / chi\n",
    "        shape = kh.shape\n",
    "\n",
    "        if b1 not in ['e', 'v', 'HI'] or b2 not in ['e', 'v', 'HI']:\n",
    "            print('b1 and b2 must be \"e\", \"v\" or \"HI\"')\n",
    "            raise\n",
    "        else:\n",
    "            if b1 == 'e': B1 = self.bias_electron\n",
    "            elif b1 == 'v': B1 = self.bias_velocity\n",
    "            elif b1 == 'HI': B1 = self.bias_HI\n",
    "\n",
    "            if b2 == 'e': B2 = self.bias_electron\n",
    "            elif b2 == 'v': B2 = self.bias_velocity\n",
    "            elif b2 == 'HI': B2 = self.bias_HI\n",
    "\n",
    "        mesh = tc.where(L <= cut_off)\n",
    "        P = (self.Pm_interpolation(kh.flatten().clone().detach(), tc.tensor([z]))).reshape(shape) * B1(kh, z) * B2(kh, z)\n",
    "\n",
    "        if b1=='v' and b2=='v' :\n",
    "            P[mesh] = 2. * self.Pm_interpolation(kh_cutoff, tc.tensor([z])) * B1(kh_cutoff, z) * B2(kh_cutoff, z)\n",
    "        elif b1=='v' or b2=='v' :\n",
    "            P[mesh] = self.Pm_interpolation(kh_cutoff, tc.tensor([z])) * B1(kh_cutoff, z) * B2(kh_cutoff, z)\n",
    "        else:\n",
    "            P[mesh] = 2./3. * self.Pm_interpolation(kh_cutoff, tc.tensor([z])) * B1(kh_cutoff, z) * B2(kh_cutoff, z)\n",
    "\n",
    "        return P\n",
    "\n",
    "\n",
    "    def bias_electron(self, kh, z): # TO BE REVISED\n",
    "        return kh/kh\n",
    "    \n",
    "    def bias_velocity(self, kh, z):\n",
    "        b = 1/(1+z) * self.H_of_z(z) * self.f_of_z(z) / kh\n",
    "        return b\n",
    "    \n",
    "    def bias_HI(self, kh, z): # TO BE REVISED\n",
    "        return kh/kh\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def Polar_dot(lx, thetax, ly, thetay):\n",
    "    return lx * ly * np.cos(thetax - thetay)\n",
    "\n",
    "def Evaluate_angle(N_vec, *vectors):\n",
    "    if 2*N_vec != len(vectors):\n",
    "        print('The input N_vec does not match the number of input vectors')\n",
    "        raise\n",
    "    else:\n",
    "        # We need to do some adjustment on vectors to match the broadcast rule\n",
    "        # In order to keep vectors unchanged, make a copy of them for calculation\n",
    "        vec = deepcopy(vectors)\n",
    "\n",
    "        l_x = 0.\n",
    "        l_y = 0.\n",
    "        for i in range(N_vec):\n",
    "            # if len(vectors[2*i]) == 1: vec[2*i] = np.array(vectors[2*i])\n",
    "            # if len(vectors[2*i+1]) == 1: vec[2*i+1] = np.array(vectors[2*i+1])\n",
    "            # print('shape1', vec[2*i].shape, '   shape2', vec[2*i+1].shape, '   shape3', np.cos(vec[2*i+1]).shape)\n",
    "            l_x = l_x + vec[2*i] * np.cos(vec[2*i+1])\n",
    "            l_y = l_y + vec[2*i] * np.sin(vec[2*i+1])\n",
    "            # print(l_x.shape, '   ', l_y.shape)\n",
    "        \n",
    "        return np.arctan2(l_y, l_x)\n",
    "    \n",
    "def interp2d_torch(x, y, z, x_new, y_new, mode='bilinear'):\n",
    "    '''\n",
    "    Interpolates 2D data over a grid using PyTorch, mimicking `scipy.interpolate.interp2d`.\n",
    "    \n",
    "    Parameters:\n",
    "        x (torch.Tensor): 1D tensor of x coordinates (size: N).\n",
    "        y (torch.Tensor): 1D tensor of y coordinates (size: M).\n",
    "        z (torch.Tensor): 2D tensor of shape (M, N) representing the grid values.\n",
    "        x_new (torch.Tensor): 1D tensor of new x coordinates for interpolation (size: N').\n",
    "        y_new (torch.Tensor): 1D tensor of new y coordinates for interpolation (size: M').\n",
    "        mode (str): Interpolation mode ('bilinear', 'nearest'). Defaults to 'bilinear'.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Interpolated values at new (x_new, y_new) grid points.\n",
    "    '''\n",
    "    \n",
    "    # Ensure the input tensors are of the correct shape\n",
    "    z = z.unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions (1, 1, M, N)\n",
    "    \n",
    "    # Create the meshgrid for new points (x_new, y_new)\n",
    "    x_new_grid, y_new_grid = tc.meshgrid(x_new, y_new, indexing='ij')\n",
    "    \n",
    "    # Normalize new grid coordinates to range [-1, 1] (for grid_sample)\n",
    "    x_min, x_max = x.min(), x.max()\n",
    "    y_min, y_max = y.min(), y.max()\n",
    "    \n",
    "    x_new_norm = 2 * (x_new_grid - x_min) / (x_max - x_min) - 1\n",
    "    y_new_norm = 2 * (y_new_grid - y_min) / (y_max - y_min) - 1\n",
    "    \n",
    "    # Stack and reshape the new coordinates into (1, H', W', 2) for grid_sample\n",
    "    grid = tc.stack((x_new_norm, y_new_norm), dim=-1).unsqueeze(0)\n",
    "    \n",
    "    # Perform the interpolation using grid_sample\n",
    "    interpolated = tc.nn.functional.grid_sample(z, grid, mode=mode, align_corners=True)\n",
    "    \n",
    "    # Remove the batch and channel dimensions and return the result\n",
    "    return interpolated.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cl_kSZ2_HI2():\n",
    "\n",
    "    def __init__(self, z_array, Tb = 1.8e-4, H0 = 67.75, ombh2 = 0.022):\n",
    "        \n",
    "        ##################################################s\n",
    "        # Define the cosmological parameters\n",
    "        params = camb.CAMBparams()\n",
    "        params.set_cosmology(H0=H0, ombh2=ombh2)\n",
    "        params.set_matter_power(redshifts = z_array, kmax=10, nonlinear=True)\n",
    "        results = camb.get_results(params)\n",
    "        backgrounds = camb.get_background(params)\n",
    "\n",
    "        # Calculate the background evolution and results\n",
    "        kh, z, Pm = results.get_matter_power_spectrum(minkh=1e-4, maxkh=10, npoints = 500, var1='delta_tot', var2='delta_tot')\n",
    "        Xe_of_z = np.array(backgrounds.get_background_redshift_evolution(z_array, ['x_e'], format='array')).flatten()\n",
    "        chi_of_z = np.array(results.comoving_radial_distance(z_array))\n",
    "\n",
    "        ##################################################\n",
    "        # Store the variables that we are interested in\n",
    "\n",
    "        # Constant scalars and arrays\n",
    "        self.TCMB = params.TCMB         # CMB temperature 2.7K\n",
    "        self.Tb = Tb                    # HI brightness temperature, in unite mK\n",
    "        self.kh_list = kh               # Total kh array that we are interested in\n",
    "        self.kh_array = tc.tensor(kh)\n",
    "        self.z_list = z                 # Total redshift array that we are interested in\n",
    "        self.z_array = tc.tensor(z)\n",
    "        \n",
    "        # Functions of redshift\n",
    "        self.H_of_z = tc.tensor(backgrounds.hubble_parameter(z))        # Hubble parameter over c, in unit h/Mpc\n",
    "        self.f_of_z = tc.tensor(                                        # Logarithmic growth rate\n",
    "            backgrounds.get_redshift_evolution([0.01], z, ['growth'])\n",
    "            ).flatten()\n",
    "        self.Xe_of_z = tc.tensor(Xe_of_z)                               # Ionized franction Xe\n",
    "        self.chi_of_z = tc.tensor(chi_of_z)                             # Comoving distance chi\n",
    "        self.F_kSZ = self.Xe_of_z * (1+z)**2 / self.chi_of_z**2         # F_kSZ, propto visibility function of kSZ\n",
    "        self.G_HI = 1 / (z[-1] - z[0]) / self.chi_of_z**2               # G_HI, proptp window function of HI\n",
    "\n",
    "        # interpolation functions of k and z\n",
    "        self.Pm = tc.tensor(Pm) # interp2d_torch(kh, z, Pm)             # Matter power spectrum\n",
    "\n",
    "        # Interpolation functions for matter power spectrum\n",
    "        # adding infrared asymptotic behavior (P proportional to k)\n",
    "        N_add = 5\n",
    "        self.kh_array_itp = tc.hstack([tc.linspace(0., kh[0], N_add), tc.tensor(kh[1:])])\n",
    "        Pm_infared = tc.linspace(0., kh[0], N_add).repeat(len(z)).reshape([len(z), N_add]) * Pm[:, :1] / kh[0]\n",
    "        self.Pm_itp = tc.hstack([Pm_infared, tc.tensor(Pm[:, 1:])])\n",
    "\n",
    "        # save the cosmological model, for checking the result\n",
    "        self.results = results\n",
    "        self.BGEvolution = backgrounds\n",
    "        \n",
    "    def Growth_Rate_of_z(self, backgrounds, itp_order):\n",
    "        '''\n",
    "        Get the interpolation function for logarithmic growth rate f, \n",
    "        defined as f:=d(ln D)/d(ln a)\n",
    "        '''\n",
    "        # Since the growth rate almost does not vary with momentum scale, we fix kh=0.01 to get f\n",
    "        f_of_z = backgrounds.get_redshift_evolution([0.01], self.z_list, ['growth'])\n",
    "        return interp1d(self.z_list, np.array(f_of_z).flatten(), kind = itp_order)\n",
    "\n",
    "    def Power_matter_1d(self, kh, zindex, Mode='cubic'):\n",
    "        return torch_interp1d(self.kh_array_itp, (self.Pm_itp)[zindex], kh)\n",
    "\n",
    "    def Pm_interpolation(self, x, y, Mode='bilinear'):\n",
    "        return interp2d_torch(self.kh_array, self.z_array, self.Pm, x, y, mode=Mode)\n",
    "\n",
    "    def dCl(self, z, l, l1, l_min = 1, l_max = 1000, N_l = 1000, N_theta = 81):\n",
    "        \"\"\"Evaluare the integrand, dCl, as a function of z, l and l_1.\n",
    "\n",
    "        Here we sum over theta_1, l_2, and theta_2. To get the final C_l result, one has to integrate dCl over chi and l_1, for a given l.\n",
    "\n",
    "        Input\n",
    "        -----\n",
    "        `z` : float. \n",
    "            The redshift. \n",
    "\n",
    "        `l` : float. \n",
    "            The moment for C_l. Don't need to be an integer since we are in flat-sky approximation.\n",
    "\n",
    "        `l1` : float.\n",
    "            The norm of \\\\vec{l}_1.\n",
    "\n",
    "        \"\"\"\n",
    "        ##################################################\n",
    "        # Redefine the inputs as tc.tensors\n",
    "        z = tc.tensor([z], dtype=tc.float64)\n",
    "        l = tc.tensor([l], dtype=tc.float64)\n",
    "        l1 = tc.tensor([l1], dtype=tc.float64)\n",
    "\n",
    "        # Make the mesh grid for theta_1, |l_2|, and theta_2\n",
    "        t1_list = tc.arange(N_theta, dtype=tc.float64) * tc.pi / N_theta\n",
    "        t2_list = deepcopy(t1_list)\n",
    "        l2_list = tc.linspace(l_min, l_max, N_l, dtype=tc.float64)\n",
    "        l2, t1, t2 = tc.meshgrid(l2_list, t1_list, t2_list, indexing='ij')\n",
    "\n",
    "        # Make the mesh grid for theta_1, |l_2|, and theta_2\n",
    "        # t1 = tc.tensor([tc.pi / 3.], dtype=tc.float64)\n",
    "        # t2_list = tc.arange(N_theta, dtype=tc.float64) * 2 * tc.pi / N_theta\n",
    "        # l2_list = tc.linspace(l_min, l_max, N_l, dtype=tc.float64) # 10**tc.linspace(np.log10(l_min), np.log10(l_max), N_l, dtype=tc.float64)\n",
    "        # l2, t2 = tc.meshgrid(l2_list, t2_list, indexing='ij')\n",
    "\n",
    "        # Pre-define useful varibales and constants\n",
    "        lsquare = l**2\n",
    "        l1square = l1**2\n",
    "        l2square = l2**2\n",
    "\n",
    "        l_dot_l1 = Polar_dot(l, 0., l1, t1)\n",
    "        l_dot_l2 = Polar_dot(l, 0., l2, t2)\n",
    "        l1_dot_l2 = Polar_dot(l1, t1, l2, t2)\n",
    "\n",
    "        l_m_l1_norm = tc.sqrt( lsquare + l1square - 2*l_dot_l1 )\n",
    "        l_p_l2_norm = tc.sqrt( lsquare + l2square + 2*l_dot_l2 )\n",
    "        l1_p_l2_norm = tc.sqrt( l1square + l2square + 2*l1_dot_l2 )\n",
    "        l_m_l1_p_l2_norm = tc.sqrt( lsquare + l1square + l2square - 2*l_dot_l1 + 2*l_dot_l2 - 2*l1_dot_l2 )\n",
    "\n",
    "        del(l_dot_l1)\n",
    "        del(l_dot_l2)\n",
    "        del(l1_dot_l2)\n",
    "\n",
    "        theta_l_p_l2 = Evaluate_angle(2, l, tc.tensor([0.]), l2, t2)\n",
    "        theta_l1_p_l2 = Evaluate_angle(2, l, tc.tensor([0.]), l2, t2)\n",
    "        theta_l_m_l1_p_l2 = Evaluate_angle(3, l, tc.tensor([0.]), -l1, t1, l2, t2)\n",
    "\n",
    "        \n",
    "\n",
    "        Z_MEAN = 0.45 # mean redshift for HI observation\n",
    "        FREQ_HI = 1420. # in unit MHz\n",
    "        SIGMA_HI = 0.0115 * 1000. * (1. + Z_MEAN) / FREQ_HI\n",
    "        SIGMA_KSZ = deepcopy(SIGMA_HI)\n",
    "\n",
    "        ##################################################\n",
    "        # Evaluate the integrand\n",
    "        # Initialization\n",
    "        dCl_tot = tc.zeros_like(t2)\n",
    "\n",
    "        # Contribution originate from each term in Wick Theorem\n",
    "        # Term 5 \n",
    "        dCl = - tc.cos(theta_l1_p_l2 - t2) # - (l_dot_l2 + l2square) / l_p_l2_norm / l2\n",
    "        dCl *= self.Cross_Power(z, l1_p_l2_norm, 'e', 'e')\n",
    "        dCl *= self.Cross_Power(z, l_p_l2_norm, 'v', 'HI')\n",
    "        dCl *= self.Cross_Power(z, l2, 'v', 'HI')\n",
    "        dCl_tot += dCl\n",
    "        # Term 6 \n",
    "        dCl = - tc.cos(theta_l1_p_l2 - t2) # - (l_dot_l2 + l2square) / l_p_l2_norm / l2\n",
    "        dCl *= self.Cross_Power(z, l_m_l1_p_l2_norm, 'e', 'e')\n",
    "        dCl *= self.Cross_Power(z, l_p_l2_norm, 'v', 'HI')\n",
    "        dCl *= self.Cross_Power(z, l2, 'v', 'HI')\n",
    "        dCl_tot += dCl\n",
    "        # Term 8 \n",
    "        dCl = tc.cos(theta_l_p_l2 - theta_l1_p_l2) # (l_dot_l1 + l_dot_l2 + l1_dot_l2 + l2square) / l_p_l2_norm / l1_p_l2_norm\n",
    "        dCl *= self.Cross_Power(z, l_m_l1_p_l2_norm, 'e', 'v')\n",
    "        dCl *= self.Cross_Power(z, l_p_l2_norm, 'e', 'HI')\n",
    "        dCl *= self.Cross_Power(z, l2, 'v', 'HI')\n",
    "        dCl_tot += dCl\n",
    "        # Term 9\n",
    "        dCl = tc.cos(theta_l_m_l1_p_l2 - t2) # (l_dot_l2 - l1_dot_l2 + l2square) / l_m_l1_p_l2_norm / l2\n",
    "        dCl *= self.Cross_Power(z, l1_p_l2_norm, 'e', 'v')\n",
    "        dCl *= self.Cross_Power(z, l2, 'e', 'HI')\n",
    "        dCl *= self.Cross_Power(z, l_p_l2_norm, 'v', 'HI')\n",
    "        dCl_tot += dCl\n",
    "        # Term 10\n",
    "        dCl = tc.cos(theta_l1_p_l2 - t2)# (l1_dot_l2 + l2square) / l1_p_l2_norm / l2\n",
    "        dCl *= self.Cross_Power(z, l_p_l2_norm, 'e', 'HI')\n",
    "        dCl *= self.Cross_Power(z, l1_p_l2_norm, 'e', 'v')\n",
    "        dCl *= self.Cross_Power(z, l2, 'v', 'HI')\n",
    "        dCl_tot += dCl\n",
    "        # Term 11\n",
    "        dCl = -1.\n",
    "        dCl *= self.Cross_Power(z, l_p_l2_norm, 'e', 'HI')\n",
    "        dCl *= self.Cross_Power(z, l1_p_l2_norm, 'v', 'v')\n",
    "        dCl *= self.Cross_Power(z, l2, 'e', 'HI')\n",
    "        dCl_tot += dCl\n",
    "        # Term 13\n",
    "        dCl = tc.cos(theta_l_m_l1_p_l2 - theta_l_p_l2) # (lsquare + l2square + 2*l_dot_l2 - l_dot_l1 - l1_dot_l2) / l_p_l2_norm / l_m_l1_p_l2_norm\n",
    "        dCl *= self.Cross_Power(z, l2, 'e', 'HI')\n",
    "        dCl *= self.Cross_Power(z, l_m_l1_p_l2_norm, 'e', 'v')\n",
    "        dCl *= self.Cross_Power(z, l1_p_l2_norm, 'v', 'HI')\n",
    "        dCl_tot += dCl\n",
    "        # Term 14\n",
    "        dCl = -1.\n",
    "        dCl = self.Cross_Power(z, l2, 'e', 'HI')\n",
    "        dCl *= self.Cross_Power(z, l_m_l1_p_l2_norm, 'v', 'v')\n",
    "        dCl *= self.Cross_Power(z, l1_p_l2_norm, 'e', 'HI')\n",
    "        dCl_tot += dCl\n",
    "\n",
    "        # The beam functions\n",
    "        dCl_tot *= self.Beam_kSZ(l_m_l1_norm, SIGMA_KSZ) * self.Beam_kSZ(l1, SIGMA_KSZ) * self.Beam_HI(l_p_l2_norm, SIGMA_HI) * self.Beam_HI(l2, SIGMA_HI)\n",
    "        # The window functions and the metric determinant contribution \n",
    "        dCl_tot *= l1 * l2 * self.F_kSZ(z)**2 * self.G_HI(z)**2 * self.dchi_by_dz(z)\n",
    "\n",
    "        print(dCl_tot.shape)\n",
    "\n",
    "        dCl_res = tc.sum(dCl_tot) * t2_list[1] * (l_max - l_min) / (N_l - 1)\n",
    "\n",
    "        return dCl_res\n",
    "    \n",
    "    def dchi_by_dz(self, z):\n",
    "        return sc.c / self.H_of_z(z)\n",
    "\n",
    "    # def F_kSZ(self, z):\n",
    "    #     return tc.tensor(self.Xe(z)) * (1+z)**2 / tc.tensor(self.chi(z))**2\n",
    "    \n",
    "    # def G_HI(self, z):\n",
    "    #     return 1 / (self.z_list[-1] - self.z_list[0]) / self.chi(z)**2\n",
    "\n",
    "    def Beam_kSZ(self, l, singma_kSZ):\n",
    "        return tc.exp(-l**2 * singma_kSZ**2 / 2)\n",
    "    \n",
    "    def Beam_HI(self, l, singma_HI):\n",
    "        return tc.exp(-l**2 * singma_HI**2 / 2)\n",
    "\n",
    "    '''def Cross_Power(self, z, L, b1, b2, cut_off= tc.tensor([2.])):\n",
    "        \n",
    "        chi = self.chi(z)\n",
    "        kh = L / chi\n",
    "        kh_cutoff = cut_off / chi\n",
    "        shape = kh.shape\n",
    "\n",
    "        if b1 not in ['e', 'v', 'HI'] or b2 not in ['e', 'v', 'HI']:\n",
    "            print('b1 and b2 must be \"e\", \"v\" or \"HI\"')\n",
    "            raise\n",
    "        else:\n",
    "            if b1 == 'e': B1 = self.bias_electron\n",
    "            elif b1 == 'v': B1 = self.bias_velocity\n",
    "            elif b1 == 'HI': B1 = self.bias_HI\n",
    "\n",
    "            if b2 == 'e': B2 = self.bias_electron\n",
    "            elif b2 == 'v': B2 = self.bias_velocity\n",
    "            elif b2 == 'HI': B2 = self.bias_HI\n",
    "\n",
    "        mesh = tc.where(L <= cut_off)\n",
    "        P = (self.Pm_interpolation(kh.flatten().clone().detach(), tc.tensor([z]))).reshape(shape) * B1(kh, z) * B2(kh, z)\n",
    "\n",
    "        if b1=='v' and b2=='v' :\n",
    "            P[mesh] = 2. * self.Pm_interpolation(kh_cutoff, tc.tensor([z])) * B1(kh_cutoff, z) * B2(kh_cutoff, z)\n",
    "        elif b1=='v' or b2=='v' :\n",
    "            P[mesh] = self.Pm_interpolation(kh_cutoff, tc.tensor([z])) * B1(kh_cutoff, z) * B2(kh_cutoff, z)\n",
    "        else:\n",
    "            P[mesh] = 2./3. * self.Pm_interpolation(kh_cutoff, tc.tensor([z])) * B1(kh_cutoff, z) * B2(kh_cutoff, z)\n",
    "\n",
    "        return P'''\n",
    "\n",
    "    def bias_electron(self, kh, z): # TO BE REVISED\n",
    "        return kh/kh\n",
    "    \n",
    "    def bias_velocity(self, kh, z, cut_off = tc.tensor([1e-6], dtype=tc.float64)):\n",
    "        z_dependence = 1/(1+z) * self.H_of_z(z) * self.f_of_z(z)\n",
    "        b = tc.where(kh > cut_off, z_dependence / kh, z_dependence / cut_off)\n",
    "        return b\n",
    "    \n",
    "    def bias_HI(self, kh, z): # TO BE REVISED\n",
    "        return kh/kh\n",
    "\n",
    "\n",
    "    \n",
    "    def dCl_test(self, z, l, l1, l_min = 1, l_max = 1000, N_l = 1000, N_theta = 81):\n",
    "        \"\"\"Evaluare the integrand, dCl, as a function of z, l and l_1.\n",
    "\n",
    "        Here we sum over theta_1, l_2, and theta_2. To get the final C_l result, one has to integrate dCl over chi and l_1, for a given l.\n",
    "\n",
    "        Input\n",
    "        -----\n",
    "        `z` : float. \n",
    "            The redshift. \n",
    "\n",
    "        `l` : float. \n",
    "            The moment for C_l. Don't need to be an integer since we are in flat-sky approximation.\n",
    "\n",
    "        `l1` : float.\n",
    "            The norm of \\\\vec{l}_1.\n",
    "\n",
    "        \"\"\"\n",
    "        ##################################################\n",
    "\n",
    "        ti = time.time()\n",
    "\n",
    "        Z_MEAN = 0.45 # mean redshift for HI observation\n",
    "        FREQ_HI = 1420. # in unit MHz\n",
    "        SIGMA_HI = 0.0115 * 1000. * (1. + Z_MEAN) / FREQ_HI\n",
    "        SIGMA_KSZ = deepcopy(SIGMA_HI)\n",
    "\n",
    "        # Redefine the inputs as tc.tensors\n",
    "        z = tc.tensor([z], dtype=tc.float64)\n",
    "        l = tc.tensor([l], dtype=tc.float64)\n",
    "        l1 = tc.tensor([l1], dtype=tc.float64)\n",
    "\n",
    "        # Make the mesh grid for theta_1, |l_2|, and theta_2\n",
    "        t1_list = tc.arange(N_theta, dtype=tc.float64) * tc.pi / N_theta\n",
    "        t2_list = deepcopy(t1_list)\n",
    "        l2_list = tc.linspace(l_min, l_max, N_l, dtype=tc.float64)\n",
    "        l2, t1, t2 = tc.meshgrid(l2_list, t1_list, t2_list, indexing='ij')\n",
    "\n",
    "        print('Making meshgrid', time.time() - ti)\n",
    "\n",
    "        # Make the mesh grid for theta_1, |l_2|, and theta_2\n",
    "        # t1 = tc.tensor([tc.pi / 3.], dtype=tc.float64)\n",
    "        # t2_list = tc.arange(N_theta, dtype=tc.float64) * 2 * tc.pi / N_theta\n",
    "        # l2_list = tc.linspace(l_min, l_max, N_l, dtype=tc.float64) # 10**tc.linspace(np.log10(l_min), np.log10(l_max), N_l, dtype=tc.float64)\n",
    "        # l2, t2 = tc.meshgrid(l2_list, t2_list, indexing='ij')\n",
    "\n",
    "        # Pre-define useful varibales and constants\n",
    "        lsquare = l**2\n",
    "        l1square = l1**2\n",
    "        l2square = l2**2\n",
    "\n",
    "        l_dot_l1 = Polar_dot(l, 0., l1, t1)\n",
    "        l_dot_l2 = Polar_dot(l, 0., l2, t2)\n",
    "        l1_dot_l2 = Polar_dot(l1, t1, l2, t2)\n",
    "        print('Evaluate dot product ', time.time() - ti)\n",
    "\n",
    "        l_m_l1_norm = tc.sqrt( lsquare + l1square - 2*l_dot_l1 )\n",
    "        l_p_l2_norm = tc.sqrt( lsquare + l2square + 2*l_dot_l2 )\n",
    "        l1_p_l2_norm = tc.sqrt( l1square + l2square + 2*l1_dot_l2 )\n",
    "        l_m_l1_p_l2_norm = tc.sqrt( lsquare + l1square + l2square - 2*l_dot_l1 + 2*l_dot_l2 - 2*l1_dot_l2 )\n",
    "        print('Evaluate norm ', time.time() - ti)\n",
    "\n",
    "        del(l_dot_l1)\n",
    "        del(l_dot_l2)\n",
    "        del(l1_dot_l2)\n",
    "        print('Delete the redundant ', time.time() - ti)\n",
    "\n",
    "        theta_l_p_l2 = Evaluate_angle(2, l, tc.tensor([0.]), l2, t2)\n",
    "        theta_l1_p_l2 = Evaluate_angle(2, l, tc.tensor([0.]), l2, t2)\n",
    "        theta_l_m_l1_p_l2 = Evaluate_angle(3, l, tc.tensor([0.]), -l1, t1, l2, t2)\n",
    "        print('Evaluate theta ', time.time() - ti)\n",
    "\n",
    "        # define the mesh\n",
    "        cut_off = tc.tensor([2.])\n",
    "        mesh_l1_p_l2_norm = tc.where(l1_p_l2_norm <= cut_off)\n",
    "        mesh_l_p_l2_norm = tc.where(l_p_l2_norm <= cut_off)\n",
    "        mesh_l2 = tc.where(l2 <= cut_off)\n",
    "        mesh_l_m_l1_p_l2_norm = tc.where(l_m_l1_p_l2_norm <= cut_off)\n",
    "        print('Define cut-off mesh ', time.time() - ti)\n",
    "        print('   ')\n",
    "\n",
    "        ##################################################\n",
    "        # Evaluate the integrand\n",
    "        # Initialization\n",
    "        dCl_tot = tc.zeros_like(t2)\n",
    "\n",
    "        # Contribution originate from each term in Wick Theorem\n",
    "        print('Term 5')# Term 5 \n",
    "        dCl = - tc.cos(theta_l1_p_l2 - t2) # - (l_dot_l2 + l2square) / l_p_l2_norm / l2\n",
    "        dCl *= self.Cross_Power(z, l1_p_l2_norm, 'e', 'e', mesh=mesh_l1_p_l2_norm, cut_off=cut_off)\n",
    "        dCl *= self.Cross_Power(z, l_p_l2_norm, 'v', 'HI', mesh=mesh_l_p_l2_norm, cut_off=cut_off)\n",
    "        dCl *= self.Cross_Power(z, l2, 'v', 'HI', mesh=mesh_l2, cut_off=cut_off)\n",
    "        dCl_tot += dCl\n",
    "        print('Term 6')# Term 6 \n",
    "        dCl = - tc.cos(theta_l1_p_l2 - t2) # - (l_dot_l2 + l2square) / l_p_l2_norm / l2\n",
    "        dCl *= self.Cross_Power(z, l_m_l1_p_l2_norm, 'e', 'e', mesh=mesh_l_m_l1_p_l2_norm, cut_off=cut_off)\n",
    "        dCl *= self.Cross_Power(z, l_p_l2_norm, 'v', 'HI', mesh=mesh_l_p_l2_norm, cut_off=cut_off)\n",
    "        dCl *= self.Cross_Power(z, l2, 'v', 'HI', mesh=mesh_l2, cut_off=cut_off)\n",
    "        dCl_tot += dCl\n",
    "        print('Term 8')# Term 8 \n",
    "        dCl = tc.cos(theta_l_p_l2 - theta_l1_p_l2) # (l_dot_l1 + l_dot_l2 + l1_dot_l2 + l2square) / l_p_l2_norm / l1_p_l2_norm\n",
    "        dCl *= self.Cross_Power(z, l_m_l1_p_l2_norm, 'e', 'v', mesh=mesh_l_m_l1_p_l2_norm, cut_off=cut_off)\n",
    "        dCl *= self.Cross_Power(z, l_p_l2_norm, 'e', 'HI', mesh=mesh_l_p_l2_norm, cut_off=cut_off)\n",
    "        dCl *= self.Cross_Power(z, l2, 'v', 'HI', mesh=mesh_l2, cut_off=cut_off)\n",
    "        dCl_tot += dCl\n",
    "        print('Term 9')# Term 9\n",
    "        dCl = tc.cos(theta_l_m_l1_p_l2 - t2) # (l_dot_l2 - l1_dot_l2 + l2square) / l_m_l1_p_l2_norm / l2\n",
    "        dCl *= self.Cross_Power(z, l1_p_l2_norm, 'e', 'v', mesh=mesh_l1_p_l2_norm, cut_off=cut_off)\n",
    "        dCl *= self.Cross_Power(z, l2, 'e', 'HI', mesh=mesh_l2, cut_off=cut_off)\n",
    "        dCl *= self.Cross_Power(z, l_p_l2_norm, 'v', 'HI', mesh=mesh_l_p_l2_norm, cut_off=cut_off)\n",
    "        dCl_tot += dCl\n",
    "        print('Term 10')# Term 10\n",
    "        dCl = tc.cos(theta_l1_p_l2 - t2)# (l1_dot_l2 + l2square) / l1_p_l2_norm / l2\n",
    "        dCl *= self.Cross_Power(z, l_p_l2_norm, 'e', 'HI', mesh=mesh_l_p_l2_norm, cut_off=cut_off)\n",
    "        dCl *= self.Cross_Power(z, l1_p_l2_norm, 'e', 'v', mesh=mesh_l1_p_l2_norm, cut_off=cut_off)\n",
    "        dCl *= self.Cross_Power(z, l2, 'v', 'HI', mesh=mesh_l2, cut_off=cut_off)\n",
    "        dCl_tot += dCl\n",
    "        print('Term 11')# Term 11\n",
    "        dCl = -1.\n",
    "        dCl *= self.Cross_Power(z, l_p_l2_norm, 'e', 'HI', mesh=mesh_l_p_l2_norm, cut_off=cut_off)\n",
    "        dCl *= self.Cross_Power(z, l1_p_l2_norm, 'v', 'v', mesh=mesh_l1_p_l2_norm, cut_off=cut_off)\n",
    "        dCl *= self.Cross_Power(z, l2, 'e', 'HI', mesh=mesh_l2, cut_off=cut_off)\n",
    "        dCl_tot += dCl\n",
    "        print('Term 13')# Term 13\n",
    "        dCl = tc.cos(theta_l_m_l1_p_l2 - theta_l_p_l2) # (lsquare + l2square + 2*l_dot_l2 - l_dot_l1 - l1_dot_l2) / l_p_l2_norm / l_m_l1_p_l2_norm\n",
    "        dCl *= self.Cross_Power(z, l2, 'e', 'HI', mesh=mesh_l2, cut_off=cut_off)\n",
    "        dCl *= self.Cross_Power(z, l_m_l1_p_l2_norm, 'e', 'v', mesh=mesh_l_m_l1_p_l2_norm, cut_off=cut_off)\n",
    "        dCl *= self.Cross_Power(z, l1_p_l2_norm, 'v', 'HI', mesh=mesh_l1_p_l2_norm, cut_off=cut_off)\n",
    "        dCl_tot += dCl\n",
    "        print('Term 14')# Term 14\n",
    "        dCl = -1.\n",
    "        dCl = self.Cross_Power(z, l2, 'e', 'HI', mesh=mesh_l2, cut_off=cut_off)\n",
    "        dCl *= self.Cross_Power(z, l_m_l1_p_l2_norm, 'v', 'v', mesh=mesh_l_m_l1_p_l2_norm, cut_off=cut_off)\n",
    "        dCl *= self.Cross_Power(z, l1_p_l2_norm, 'e', 'HI', mesh=mesh_l1_p_l2_norm, cut_off=cut_off)\n",
    "        dCl_tot += dCl\n",
    "\n",
    "        tf = time.time()\n",
    "        # The beam functions\n",
    "        dCl_tot *= self.Beam_kSZ(l_m_l1_norm, SIGMA_KSZ) * self.Beam_kSZ(l1, SIGMA_KSZ) * self.Beam_HI(l_p_l2_norm, SIGMA_HI) * self.Beam_HI(l2, SIGMA_HI)\n",
    "        # The window functions and the metric determinant contribution \n",
    "        dCl_tot *= l1 * l2 * self.F_kSZ(z)**2 * self.G_HI(z)**2 * self.dchi_by_dz(z)\n",
    "        print('Taking in beams ', time.time() - tf)\n",
    "\n",
    "        # print(dCl_tot.shape)\n",
    "\n",
    "        dCl_res = tc.sum(dCl_tot) * t2_list[1] * (l_max - l_min) / (N_l - 1)\n",
    "        print('Summation ', time.time() - tf)\n",
    "\n",
    "        return dCl_res\n",
    "    \n",
    "    def Cross_Power_i(self, z, L, b1, b2, mesh, cut_off):\n",
    "        \n",
    "        chi = self.chi(z)\n",
    "        kh = L / chi\n",
    "        kh_cutoff = cut_off / chi\n",
    "        shape = kh.shape\n",
    "\n",
    "        if b1 not in ['e', 'v', 'HI'] or b2 not in ['e', 'v', 'HI']:\n",
    "            print('b1 and b2 must be \"e\", \"v\" or \"HI\"')\n",
    "            raise\n",
    "        else:\n",
    "            if b1 == 'e': B1 = self.bias_electron\n",
    "            elif b1 == 'v': B1 = self.bias_velocity\n",
    "            elif b1 == 'HI': B1 = self.bias_HI\n",
    "\n",
    "            if b2 == 'e': B2 = self.bias_electron\n",
    "            elif b2 == 'v': B2 = self.bias_velocity\n",
    "            elif b2 == 'HI': B2 = self.bias_HI\n",
    "\n",
    "        P = (self.Pm_interpolation(kh.flatten().clone().detach(), tc.tensor([z]))).reshape(shape) * B1(kh, z) * B2(kh, z)\n",
    "\n",
    "        if b1=='v' and b2=='v' :\n",
    "            P[mesh] = 2. * self.Pm_interpolation(kh_cutoff, tc.tensor([z])) * B1(kh_cutoff, z) * B2(kh_cutoff, z)\n",
    "        elif b1=='v' or b2=='v' :\n",
    "            P[mesh] = self.Pm_interpolation(kh_cutoff, tc.tensor([z])) * B1(kh_cutoff, z) * B2(kh_cutoff, z)\n",
    "        else:\n",
    "            P[mesh] = 2./3. * self.Pm_interpolation(kh_cutoff, tc.tensor([z])) * B1(kh_cutoff, z) * B2(kh_cutoff, z)\n",
    "\n",
    "        return P\n",
    "          \n",
    "    def Cross_Power(self, z, L, b1, b2, mesh, cut_off):\n",
    "        \n",
    "        t0 = time.time()\n",
    "        \n",
    "        chi = self.chi(z)\n",
    "        kh = L / chi\n",
    "        kh_cutoff = cut_off / chi\n",
    "        shape = kh.shape\n",
    "\n",
    "        if b1 not in ['e', 'v', 'HI'] or b2 not in ['e', 'v', 'HI']:\n",
    "            print('b1 and b2 must be \"e\", \"v\" or \"HI\"')\n",
    "            raise\n",
    "        else:\n",
    "            if b1 == 'e': B1 = self.bias_electron\n",
    "            elif b1 == 'v': B1 = self.bias_velocity\n",
    "            elif b1 == 'HI': B1 = self.bias_HI\n",
    "\n",
    "            print('load in b1', time.time() - t0)\n",
    "\n",
    "            if b2 == 'e': B2 = self.bias_electron\n",
    "            elif b2 == 'v': B2 = self.bias_velocity\n",
    "            elif b2 == 'HI': B2 = self.bias_HI\n",
    "\n",
    "            print('load in b2', time.time() - t0)\n",
    "\n",
    "        itp = self.Pm_interpolation(kh.flatten().clone().detach(), tc.tensor([z])).reshape(shape)\n",
    "        print('Interpolation', time.time() - t0)\n",
    "\n",
    "        P = itp * B1(kh, z) * B2(kh, z)\n",
    "        print('Multiply ', time.time() - t0)\n",
    "\n",
    "        if b1=='v' and b2=='v' :\n",
    "            P[mesh] = 2. * self.Pm_interpolation(kh_cutoff, tc.tensor([z])) * B1(kh_cutoff, z) * B2(kh_cutoff, z)\n",
    "            print('Mesh re-compute time', time.time() - t0)\n",
    "        elif b1=='v' or b2=='v' :\n",
    "            P[mesh] = self.Pm_interpolation(kh_cutoff, tc.tensor([z])) * B1(kh_cutoff, z) * B2(kh_cutoff, z)\n",
    "            print('Mesh re-compute time', time.time() - t0)\n",
    "        else:\n",
    "            P[mesh] = 2./3. * self.Pm_interpolation(kh_cutoff, tc.tensor([z])) * B1(kh_cutoff, z) * B2(kh_cutoff, z)\n",
    "            print('Mesh re-compute time', time.time() - t0)\n",
    "\n",
    "        print('   ')\n",
    "        return P\n",
    "\n",
    "\n",
    "\n",
    "def Polar_dot(lx, thetax, ly, thetay):\n",
    "    return lx * ly * np.cos(thetax - thetay)\n",
    "\n",
    "def Evaluate_angle(N_vec, *vectors):\n",
    "\n",
    "    if 2*N_vec != len(vectors):\n",
    "        print('The input N_vec does not match the number of input vectors')\n",
    "        raise\n",
    "    else:\n",
    "        # We need to do some adjustment on vectors to match the broadcast rule\n",
    "        # In order to keep vectors unchanged, make a copy of them for calculation\n",
    "        vec = deepcopy(vectors)\n",
    "\n",
    "        l_x = 0.\n",
    "        l_y = 0.\n",
    "        for i in range(N_vec):\n",
    "            # if len(vectors[2*i]) == 1: vec[2*i] = np.array(vectors[2*i])\n",
    "            # if len(vectors[2*i+1]) == 1: vec[2*i+1] = np.array(vectors[2*i+1])\n",
    "            # print('shape1', vec[2*i].shape, '   shape2', vec[2*i+1].shape, '   shape3', np.cos(vec[2*i+1]).shape)\n",
    "            l_x = l_x + vec[2*i] * np.cos(vec[2*i+1])\n",
    "            l_y = l_y + vec[2*i] * np.sin(vec[2*i+1])\n",
    "            # print(l_x.shape, '   ', l_y.shape)\n",
    "        \n",
    "        return np.arctan2(l_y, l_x)\n",
    "    \n",
    "def interp2d_torch(x, y, z, x_new, y_new, mode='bilinear'):\n",
    "    '''\n",
    "    Interpolates 2D data over a grid using PyTorch, mimicking `scipy.interpolate.interp2d`.\n",
    "    \n",
    "    Parameters:\n",
    "        x (torch.Tensor): 1D tensor of x coordinates (size: N).\n",
    "        y (torch.Tensor): 1D tensor of y coordinates (size: M).\n",
    "        z (torch.Tensor): 2D tensor of shape (M, N) representing the grid values.\n",
    "        x_new (torch.Tensor): 1D tensor of new x coordinates for interpolation (size: N').\n",
    "        y_new (torch.Tensor): 1D tensor of new y coordinates for interpolation (size: M').\n",
    "        mode (str): Interpolation mode ('bilinear', 'nearest'). Defaults to 'bilinear'.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Interpolated values at new (x_new, y_new) grid points.\n",
    "    '''\n",
    "    \n",
    "    # Ensure the input tensors are of the correct shape\n",
    "\n",
    "    z = z.unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions (1, 1, M, N)\n",
    "    \n",
    "    # Create the meshgrid for new points (x_new, y_new)\n",
    "    x_new_grid, y_new_grid = tc.meshgrid(x_new, y_new, indexing='ij')\n",
    "    \n",
    "    # Normalize new grid coordinates to range [-1, 1] (for grid_sample)\n",
    "    x_min, x_max = x.min(), x.max()\n",
    "    y_min, y_max = y.min(), y.max()\n",
    "    \n",
    "    x_new_norm = 2 * (x_new_grid - x_min) / (x_max - x_min) - 1\n",
    "    y_new_norm = 2 * (y_new_grid - y_min) / (y_max - y_min) - 1\n",
    "    \n",
    "    # Stack and reshape the new coordinates into (1, H', W', 2) for grid_sample\n",
    "    grid = tc.stack((x_new_norm, y_new_norm), dim=-1).unsqueeze(0)\n",
    "    \n",
    "    # Perform the interpolation using grid_sample\n",
    "    interpolated = tc.nn.functional.grid_sample(z, grid, mode=mode, align_corners=True)\n",
    "    \n",
    "    # Remove the batch and channel dimensions and return the result\n",
    "    return interpolated.squeeze()\n",
    "\n",
    "def torch_interp1d(x, y, x_query):\n",
    "\n",
    "    indices = tc.searchsorted(x, x_query) - 1\n",
    "    indices = tc.clamp(indices, 0, len(x) - 2)\n",
    "\n",
    "    x0 = x[indices]\n",
    "    x1 = x[indices + 1]\n",
    "    y0 = y[indices]\n",
    "    y1 = y[indices + 1]\n",
    "\n",
    "    slope = (y1 - y0) / (x1 - x0)\n",
    "    y_query = y0 + slope * (x_query - x0)\n",
    "    \n",
    "    return y_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cl_kSZ2_HI2():\n",
    "\n",
    "    def __init__(self, z_array, Tb = 1.8e-4, H0 = 67.75, ombh2 = 0.022):\n",
    "        \n",
    "        ##################################################s\n",
    "        # Define the cosmological parameters\n",
    "        params = camb.CAMBparams()\n",
    "        params.set_cosmology(H0=H0, ombh2=ombh2)\n",
    "        params.set_matter_power(redshifts = z_array, kmax=10, nonlinear=True)\n",
    "        results = camb.get_results(params)\n",
    "        backgrounds = camb.get_background(params)\n",
    "\n",
    "        # Calculate the background evolution and results\n",
    "        kh, z, Pm = results.get_matter_power_spectrum(minkh=1e-4, maxkh=10, npoints = 500, var1='delta_tot', var2='delta_tot')\n",
    "        Xe_of_z = np.array(backgrounds.get_background_redshift_evolution(z_array, ['x_e'], format='array')).flatten()\n",
    "        chi_of_z = np.array(results.comoving_radial_distance(z_array))\n",
    "\n",
    "        ##################################################\n",
    "        # Store the variables that we are interested in\n",
    "\n",
    "        # Instruments' properties\n",
    "        Z_MEAN = 0.45 # mean redshift for HI observation\n",
    "        FREQ_HI = 1420. # in unit MHz\n",
    "        self.SIGMA_HI = 0.0115 * 1000. * (1. + Z_MEAN) / FREQ_HI\n",
    "        self.SIGMA_KSZ = deepcopy(self.SIGMA_HI)\n",
    "\n",
    "        # Constant scalars and arrays\n",
    "        self.TCMB = params.TCMB     # CMB temperature 2.7K\n",
    "        self.Tb = Tb                # HI brightness temperature, in unite mK\n",
    "        self.kh_list = kh           # Total kh array that we are interested in\n",
    "        self.kh_array = tc.tensor(kh)\n",
    "        self.z_list = z             # Total redshift array that we are interested in\n",
    "        self.z_array = tc.tensor(z)\n",
    "        self.Pm = tc.tensor(Pm)     # Matter power spectrum\n",
    "\n",
    "        # Functions of redshift\n",
    "        self.H_of_z = tc.tensor(backgrounds.hubble_parameter(z)) / sc.c     # Hubble parameter over c, in unit h/Mpc\n",
    "        self.f_of_z = tc.tensor(                                            # Logarithmic growth rate\n",
    "            backgrounds.get_redshift_evolution([0.01], z, ['growth']) ).flatten()\n",
    "        self.Xe_of_z = tc.tensor(Xe_of_z)                                   # Ionized franction Xe\n",
    "        self.chi_of_z = tc.tensor(chi_of_z)                                 # Comoving distance chi, in unit Mpc/h\n",
    "        self.dchi_by_dz = 1. / self.H_of_z                                  # Comoving distance growth rate dchi/dz\n",
    "        self.F_kSZ = self.Xe_of_z * (1+self.z_array)**2 / self.chi_of_z**2  # F_kSZ, propto visibility function of kSZ\n",
    "        self.G_HI = 1 / (z[-1] - z[0]) / self.chi_of_z**2                   # G_HI, proptp window function of HI\n",
    "\n",
    "        # Interpolation functions for matter power spectrum\n",
    "        # adding infrared asymptotic behavior (P proportional to k)\n",
    "        N_add = 5\n",
    "        self.kh_array_itp = tc.hstack([tc.linspace(0., kh[0], N_add), tc.tensor(kh[1:])])\n",
    "        Pm_infared = tc.linspace(0., kh[0], N_add).repeat(len(z)).reshape([len(z), N_add]) * Pm[:, :1] / kh[0]\n",
    "        self.Pm_itp = tc.hstack([Pm_infared, tc.tensor(Pm[:, 1:])])\n",
    "\n",
    "        # save the cosmological model, for checking the result\n",
    "        self.results = results\n",
    "        self.BGEvolution = backgrounds\n",
    "        \n",
    "    def Growth_Rate_of_z(self, backgrounds, itp_order):\n",
    "        '''\n",
    "        Get the interpolation function for logarithmic growth rate f, \n",
    "        defined as f:=d(ln D)/d(ln a)\n",
    "        '''\n",
    "        # Since the growth rate almost does not vary with momentum scale, we fix kh=0.01 to get f\n",
    "        f_of_z = backgrounds.get_redshift_evolution([0.01], self.z_list, ['growth'])\n",
    "        return interp1d(self.z_list, np.array(f_of_z).flatten(), kind = itp_order)\n",
    "    \n",
    "    def Power_matter_1d(self, kh, zindex):\n",
    "        return torch_interp1d(self.kh_array_itp, (self.Pm_itp)[zindex], kh)\n",
    "\n",
    "    def Beam_kSZ(self, l):\n",
    "        return tc.exp(-l**2 * self.SIGMA_KSZ**2 / 2)\n",
    "    \n",
    "    def Beam_HI(self, l):\n",
    "        return tc.exp(-l**2 * self.SIGMA_HI**2 / 2)\n",
    "\n",
    "    def Cross_Power(self, z, L, b1, b2, cut_off= tc.tensor([2.])):\n",
    "        \n",
    "        chi = self.chi(z)\n",
    "        kh = L / chi\n",
    "        kh_cutoff = cut_off / chi\n",
    "        shape = kh.shape\n",
    "\n",
    "        if b1 not in ['e', 'v', 'HI'] or b2 not in ['e', 'v', 'HI']:\n",
    "            print('b1 and b2 must be \"e\", \"v\" or \"HI\"')\n",
    "            raise\n",
    "        else:\n",
    "            if b1 == 'e': B1 = self.bias_electron\n",
    "            elif b1 == 'v': B1 = self.bias_velocity\n",
    "            elif b1 == 'HI': B1 = self.bias_HI\n",
    "\n",
    "            if b2 == 'e': B2 = self.bias_electron\n",
    "            elif b2 == 'v': B2 = self.bias_velocity\n",
    "            elif b2 == 'HI': B2 = self.bias_HI\n",
    "\n",
    "        mesh = tc.where(L <= cut_off)\n",
    "        P = (self.Pm_interpolation(kh.flatten().clone().detach(), tc.tensor([z]))).reshape(shape) * B1(kh, z) * B2(kh, z)\n",
    "\n",
    "        if b1=='v' and b2=='v' :\n",
    "            P[mesh] = 2. * self.Pm_interpolation(kh_cutoff, tc.tensor([z])) * B1(kh_cutoff, z) * B2(kh_cutoff, z)\n",
    "        elif b1=='v' or b2=='v' :\n",
    "            P[mesh] = self.Pm_interpolation(kh_cutoff, tc.tensor([z])) * B1(kh_cutoff, z) * B2(kh_cutoff, z)\n",
    "        else:\n",
    "            P[mesh] = 2./3. * self.Pm_interpolation(kh_cutoff, tc.tensor([z])) * B1(kh_cutoff, z) * B2(kh_cutoff, z)\n",
    "\n",
    "        return P\n",
    "\n",
    "    def bias_electron(self, kh, zindex): # TO BE REVISED\n",
    "        return kh/kh\n",
    "    \n",
    "    def bias_velocity(self, kh, zindex, cut_off = tc.tensor([1e-6], dtype=tc.float64)):\n",
    "        z_dependence = 1/(1+self.z_array[zindex]) * self.H_of_z[zindex] * self.f_of_z[zindex]\n",
    "        # cut off the divergence at infrared\n",
    "        return tc.where(kh > cut_off, z_dependence / kh, z_dependence / cut_off)\n",
    "    \n",
    "    def bias_HI(self, kh, zindex): # TO BE REVISED\n",
    "        return kh/kh\n",
    "    \n",
    "    \n",
    "    def dCl(self, zi, l, l1, l_min = 1, l_max = 800, N_l = 1600, N_theta = 243):\n",
    "        \"\"\"Evaluare the integrand, dCl, as a function of z, l and l_1.\n",
    "\n",
    "        Here we sum over theta_1, l_2, and theta_2. To get the final C_l result, one has to integrate dCl over chi and l_1, for a given l.\n",
    "\n",
    "        Input\n",
    "        -----\n",
    "        `z` : float. \n",
    "            The redshift. \n",
    "\n",
    "        `l` : float. \n",
    "            The moment for C_l. Don't need to be an integer since we are in flat-sky approximation.\n",
    "\n",
    "        `l1` : float.\n",
    "            The norm of \\\\vec{l}_1.\n",
    "\n",
    "        \"\"\"\n",
    "        ##################################################\n",
    "        # Redefine the inputs as tc.tensors\n",
    "        # z = tc.tensor([self.z_list[zindex]], dtype=tc.float64)\n",
    "        l = tc.tensor([l], dtype=tc.float64)\n",
    "        l1 = tc.tensor([l1], dtype=tc.float64)\n",
    "\n",
    "        # Make the mesh grid for theta_1, |l_2|, and theta_2\n",
    "        t1_list = tc.arange(N_theta, dtype=tc.float64) * tc.pi / N_theta\n",
    "        t2_list = deepcopy(t1_list)\n",
    "        l2_list = tc.linspace(l_min, l_max, N_l, dtype=tc.float64)\n",
    "        l2, t1, t2 = tc.meshgrid(l2_list, t1_list, t2_list, indexing='ij')\n",
    "\n",
    "        # # Make the mesh grid for theta_1, |l_2|, and theta_2\n",
    "        # t1 = tc.tensor([tc.pi / 3.], dtype=tc.float64)\n",
    "        # t2_list = tc.arange(N_theta, dtype=tc.float64) * 2 * tc.pi / N_theta\n",
    "        # l2_list = tc.linspace(l_min, l_max, N_l, dtype=tc.float64) # 10**tc.linspace(np.log10(l_min), np.log10(l_max), N_l, dtype=tc.float64)\n",
    "        # l2, t2 = tc.meshgrid(l2_list, t2_list, indexing='ij')\n",
    "\n",
    "        # Pre-define useful varibales and constants\n",
    "        chi = self.chi_of_z[zi]\n",
    "        lsquare = l**2\n",
    "        l1square = l1**2\n",
    "        l2square = l2**2\n",
    "\n",
    "        l_dot_l1 = Polar_dot(l, 0., l1, t1)\n",
    "        l_dot_l2 = Polar_dot(l, 0., l2, t2)\n",
    "        l1_dot_l2 = Polar_dot(l1, t1, l2, t2)\n",
    "\n",
    "        k_l1_p_l2_norm = tc.sqrt( l1square + l2square + 2*l1_dot_l2 ) / chi\n",
    "        k_l_p_l2_norm = tc.sqrt( lsquare + l2square + 2*l_dot_l2 ) / chi\n",
    "        k_l_m_l1_p_l2_norm = tc.sqrt( lsquare + l1square + l2square - 2*l_dot_l1 + 2*l_dot_l2 - 2*l1_dot_l2 ) / chi\n",
    "        k_l2 = l2 / chi\n",
    "\n",
    "        # Delete redundant variables to save memory\n",
    "        del(l_dot_l1, l_dot_l2, l1_dot_l2)\n",
    "\n",
    "        theta_l_p_l2 = Evaluate_angle(2, l, tc.tensor([0.]), l2, t2)\n",
    "        theta_l1_p_l2 = Evaluate_angle(2, l, tc.tensor([0.]), l2, t2)\n",
    "        theta_l_m_l1_p_l2 = Evaluate_angle(3, l, tc.tensor([0.]), -l1, t1, l2, t2)\n",
    "\n",
    "        # Pre-calculate the matter power spectrum\n",
    "        P_l1_p_l2_norm = self.Power_matter_1d(k_l1_p_l2_norm, zi)\n",
    "        P_l_p_l2_norm = self.Power_matter_1d(k_l_p_l2_norm, zi)\n",
    "        P_l2 = self.Power_matter_1d(k_l2, zi)\n",
    "        P_l_m_l1_p_l2_norm = self.Power_matter_1d(k_l_m_l1_p_l2_norm, zi)\n",
    "       \n",
    "\n",
    "        ##################################################\n",
    "        # Evaluate the integrand\n",
    "        # Initialization\n",
    "        dCl_tot = tc.zeros_like(t2)\n",
    "\n",
    "        # Contribution originate from each term in Wick Theorem\n",
    "        # Term 5 and Term 6\n",
    "        dCl = - tc.cos(theta_l1_p_l2 - t2)\n",
    "        dCl *= P_l1_p_l2_norm * self.bias_electron(k_l1_p_l2_norm,zi)**2 + P_l_m_l1_p_l2_norm * self.bias_electron(k_l_m_l1_p_l2_norm,zi)**2\n",
    "        dCl *= P_l_p_l2_norm        * self.bias_velocity(k_l1_p_l2_norm,zi)     * self.bias_HI(k_l1_p_l2_norm,zi)\n",
    "        dCl *= P_l2                 * self.bias_velocity(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        dCl_tot += dCl\n",
    "        # Term 8 \n",
    "        dCl = tc.cos(theta_l_p_l2 - theta_l1_p_l2)\n",
    "        dCl *= P_l_m_l1_p_l2_norm   * self.bias_electron(k_l_m_l1_p_l2_norm,zi) * self.bias_velocity(k_l_m_l1_p_l2_norm,zi)\n",
    "        dCl *= P_l_p_l2_norm        * self.bias_electron(k_l_p_l2_norm,zi)      * self.bias_HI(k_l_p_l2_norm,zi)\n",
    "        dCl *= P_l2                 * self.bias_velocity(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        dCl_tot += dCl\n",
    "        # Term 9\n",
    "        dCl = tc.cos(theta_l_m_l1_p_l2 - t2)\n",
    "        dCl *= P_l1_p_l2_norm       * self.bias_electron(k_l1_p_l2_norm,zi)     * self.bias_velocity(k_l1_p_l2_norm,zi)\n",
    "        dCl *= P_l2                 * self.bias_electron(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        dCl *= P_l_p_l2_norm        * self.bias_velocity(k_l_p_l2_norm,zi)      * self.bias_HI(k_l_p_l2_norm,zi)\n",
    "        dCl_tot += dCl\n",
    "        # Term 10\n",
    "        dCl = tc.cos(theta_l1_p_l2 - t2)\n",
    "        dCl *= P_l_p_l2_norm        * self.bias_electron(k_l_p_l2_norm,zi)      * self.bias_HI(k_l_p_l2_norm,zi)\n",
    "        dCl *= P_l1_p_l2_norm       * self.bias_electron(k_l1_p_l2_norm,zi)     * self.bias_velocity(k_l1_p_l2_norm,zi)\n",
    "        dCl *= P_l2                 * self.bias_velocity(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        dCl_tot += dCl\n",
    "        # Term 11\n",
    "        dCl = -1.\n",
    "        dCl *= P_l_p_l2_norm        * self.bias_electron(k_l_p_l2_norm,zi)      * self.bias_HI(k_l_p_l2_norm,zi)\n",
    "        dCl *= P_l1_p_l2_norm       * self.bias_velocity(k_l1_p_l2_norm,zi)     * self.bias_velocity(k_l1_p_l2_norm,zi)\n",
    "        dCl *= P_l2                 * self.bias_electron(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        dCl_tot += dCl\n",
    "        # Term 13\n",
    "        dCl = tc.cos(theta_l_m_l1_p_l2 - theta_l_p_l2)\n",
    "        dCl *= P_l2                 * self.bias_electron(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        dCl *= P_l_m_l1_p_l2_norm   * self.bias_electron(k_l_m_l1_p_l2_norm,zi) * self.bias_velocity(k_l_m_l1_p_l2_norm,zi)\n",
    "        dCl *= P_l1_p_l2_norm       * self.bias_velocity(k_l1_p_l2_norm,zi)     * self.bias_HI(k_l1_p_l2_norm,zi)\n",
    "        dCl_tot += dCl\n",
    "        # Term 14\n",
    "        dCl = -1.\n",
    "        dCl *= P_l2                 * self.bias_electron(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        dCl *= P_l_m_l1_p_l2_norm   * self.bias_velocity(k_l_m_l1_p_l2_norm,zi) * self.bias_velocity(k_l_m_l1_p_l2_norm,zi)\n",
    "        dCl *= P_l1_p_l2_norm       * self.bias_electron(k_l1_p_l2_norm,zi)     * self.bias_HI(k_l1_p_l2_norm,zi)\n",
    "        dCl_tot += dCl\n",
    "\n",
    "        # Delete redundant variables to save memory\n",
    "        del(P_l1_p_l2_norm, P_l_p_l2_norm, P_l2, P_l_m_l1_p_l2_norm)\n",
    "        # The beam functions\n",
    "        l_m_l1_norm = tc.sqrt( lsquare + l1square - 2*l_dot_l1 )\n",
    "        l_p_l2_norm = tc.sqrt( lsquare + l2square + 2*l_dot_l2 )\n",
    "        dCl_tot *= self.Beam_kSZ(l_m_l1_norm) * self.Beam_kSZ(l1) * self.Beam_HI(l_p_l2_norm) * self.Beam_HI(l2)\n",
    "        # The window functions and the metric determinant contribution \n",
    "        dCl_tot *= l1 * l2 * self.F_kSZ[zi]**2 * self.G_HI[zi]**2 * self.dchi_by_dz[zi]\n",
    "\n",
    "        dCl_res = tc.sum(dCl_tot) * t2_list[1]**2 * ((l_max - l_min) / (N_l - 1))**2\n",
    "\n",
    "        return dCl_res\n",
    "\n",
    "    \n",
    "    def dCl_timer(self, zi, l, l1, l_min = 1, l_max = 800, N_l = 1600, N_theta = 243):\n",
    "        \"\"\"Evaluare the integrand, dCl, as a function of z, l and l_1.\n",
    "\n",
    "        Here we sum over theta_1, l_2, and theta_2. To get the final C_l result, one has to integrate dCl over chi and l_1, for a given l.\n",
    "\n",
    "        Input\n",
    "        -----\n",
    "        `z` : float. \n",
    "            The redshift. \n",
    "\n",
    "        `l` : float. \n",
    "            The moment for C_l. Don't need to be an integer since we are in flat-sky approximation.\n",
    "\n",
    "        `l1` : float.\n",
    "            The norm of \\\\vec{l}_1.\n",
    "\n",
    "        \"\"\"\n",
    "        ##################################################\n",
    "        # Redefine the inputs as tc.tensors\n",
    "\n",
    "        t0 = time.time()\n",
    "        # z = tc.tensor([self.z_list[zindex]], dtype=tc.float64)\n",
    "        l = tc.tensor([l], dtype=tc.float64)\n",
    "        l1 = tc.tensor([l1], dtype=tc.float64)\n",
    "\n",
    "        # Make the mesh grid for theta_1, |l_2|, and theta_2\n",
    "        t1_list = tc.arange(N_theta, dtype=tc.float64) * tc.pi / N_theta\n",
    "        t2_list = deepcopy(t1_list)\n",
    "        l2_list = tc.linspace(l_min, l_max, N_l, dtype=tc.float64)\n",
    "        l2, t1, t2 = tc.meshgrid(l2_list, t1_list, t2_list, indexing='ij')\n",
    "\n",
    "        print('Meshgrid finished ', time.time() - t0)\n",
    "        # # Make the mesh grid for theta_1, |l_2|, and theta_2\n",
    "        # t1 = tc.tensor([tc.pi / 3.], dtype=tc.float64)\n",
    "        # t2_list = tc.arange(N_theta, dtype=tc.float64) * 2 * tc.pi / N_theta\n",
    "        # l2_list = tc.linspace(l_min, l_max, N_l, dtype=tc.float64) # 10**tc.linspace(np.log10(l_min), np.log10(l_max), N_l, dtype=tc.float64)\n",
    "        # l2, t2 = tc.meshgrid(l2_list, t2_list, indexing='ij')\n",
    "\n",
    "        # Pre-define useful varibales and constants\n",
    "        chi = self.chi_of_z[zi]\n",
    "        lsquare = l**2\n",
    "        l1square = l1**2\n",
    "        l2square = l2**2\n",
    "\n",
    "        l_dot_l1 = Polar_dot(l, 0., l1, t1)\n",
    "        l_dot_l2 = Polar_dot(l, 0., l2, t2)\n",
    "        l1_dot_l2 = Polar_dot(l1, t1, l2, t2)\n",
    "\n",
    "        k_l1_p_l2_norm = tc.sqrt( l1square + l2square + 2*l1_dot_l2 ) / chi\n",
    "        k_l_p_l2_norm = tc.sqrt( lsquare + l2square + 2*l_dot_l2 ) / chi\n",
    "        k_l_m_l1_p_l2_norm = tc.sqrt( lsquare + l1square + l2square - 2*l_dot_l1 + 2*l_dot_l2 - 2*l1_dot_l2 ) / chi\n",
    "        k_l2 = l2 / chi\n",
    "\n",
    "        print('k norms have been evaluated ', time.time() - t0)\n",
    "        # Delete redundant variables to save memory\n",
    "        del(l1_dot_l2)\n",
    "\n",
    "        theta_l_p_l2 = Evaluate_angle(2, l, tc.tensor([0.]), l2, t2)\n",
    "        theta_l1_p_l2 = Evaluate_angle(2, l, tc.tensor([0.]), l2, t2)\n",
    "        theta_l_m_l1_p_l2 = Evaluate_angle(3, l, tc.tensor([0.]), -l1, t1, l2, t2)\n",
    "        print('Angles have been evaluated ', time.time() - t0)\n",
    "\n",
    "        # Pre-calculate the matter power spectrum\n",
    "        P_l1_p_l2_norm = self.Power_matter_1d(k_l1_p_l2_norm, zi)\n",
    "        P_l_p_l2_norm = self.Power_matter_1d(k_l_p_l2_norm, zi)\n",
    "        P_l2 = self.Power_matter_1d(k_l2, zi)\n",
    "        P_l_m_l1_p_l2_norm = self.Power_matter_1d(k_l_m_l1_p_l2_norm, zi)\n",
    "        print('Powers have been evaluated ', time.time() - t0)\n",
    "       \n",
    "\n",
    "        ##################################################\n",
    "        # Evaluate the integrand\n",
    "        # Initialization\n",
    "        dCl_tot = tc.zeros_like(t2)\n",
    "\n",
    "        # Contribution originate from each term in Wick Theorem\n",
    "        # Term 5 and Term 6\n",
    "        dCl = - tc.cos(theta_l1_p_l2 - t2)\n",
    "        dCl *= P_l1_p_l2_norm * self.bias_electron(k_l1_p_l2_norm,zi)**2 + P_l_m_l1_p_l2_norm * self.bias_electron(k_l_m_l1_p_l2_norm,zi)**2\n",
    "        dCl *= P_l_p_l2_norm        * self.bias_velocity(k_l1_p_l2_norm,zi)     * self.bias_HI(k_l1_p_l2_norm,zi)\n",
    "        dCl *= P_l2                 * self.bias_velocity(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        dCl_tot += dCl\n",
    "        print('Term 5 and 6', time.time() - t0)\n",
    "        # Term 8 \n",
    "        dCl = tc.cos(theta_l_p_l2 - theta_l1_p_l2)\n",
    "        dCl *= P_l_m_l1_p_l2_norm   * self.bias_electron(k_l_m_l1_p_l2_norm,zi) * self.bias_velocity(k_l_m_l1_p_l2_norm,zi)\n",
    "        dCl *= P_l_p_l2_norm        * self.bias_electron(k_l_p_l2_norm,zi)      * self.bias_HI(k_l_p_l2_norm,zi)\n",
    "        dCl *= P_l2                 * self.bias_velocity(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        dCl_tot += dCl\n",
    "        print('Term 8', time.time() - t0)\n",
    "        # Term 9\n",
    "        dCl = tc.cos(theta_l_m_l1_p_l2 - t2)\n",
    "        dCl *= P_l1_p_l2_norm       * self.bias_electron(k_l1_p_l2_norm,zi)     * self.bias_velocity(k_l1_p_l2_norm,zi)\n",
    "        dCl *= P_l2                 * self.bias_electron(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        dCl *= P_l_p_l2_norm        * self.bias_velocity(k_l_p_l2_norm,zi)      * self.bias_HI(k_l_p_l2_norm,zi)\n",
    "        dCl_tot += dCl\n",
    "        print('Term 9', time.time() - t0)\n",
    "        # Term 10\n",
    "        dCl = tc.cos(theta_l1_p_l2 - t2)\n",
    "        dCl *= P_l_p_l2_norm        * self.bias_electron(k_l_p_l2_norm,zi)      * self.bias_HI(k_l_p_l2_norm,zi)\n",
    "        dCl *= P_l1_p_l2_norm       * self.bias_electron(k_l1_p_l2_norm,zi)     * self.bias_velocity(k_l1_p_l2_norm,zi)\n",
    "        dCl *= P_l2                 * self.bias_velocity(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        dCl_tot += dCl\n",
    "        print('Term 10', time.time() - t0)\n",
    "        # Term 11\n",
    "        dCl = -1.\n",
    "        dCl *= P_l_p_l2_norm        * self.bias_electron(k_l_p_l2_norm,zi)      * self.bias_HI(k_l_p_l2_norm,zi)\n",
    "        dCl *= P_l1_p_l2_norm       * self.bias_velocity(k_l1_p_l2_norm,zi)     * self.bias_velocity(k_l1_p_l2_norm,zi)\n",
    "        dCl *= P_l2                 * self.bias_electron(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        dCl_tot += dCl\n",
    "        print('Term 11', time.time() - t0)\n",
    "        # Term 13\n",
    "        dCl = tc.cos(theta_l_m_l1_p_l2 - theta_l_p_l2)\n",
    "        dCl *= P_l2                 * self.bias_electron(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        dCl *= P_l_m_l1_p_l2_norm   * self.bias_electron(k_l_m_l1_p_l2_norm,zi) * self.bias_velocity(k_l_m_l1_p_l2_norm,zi)\n",
    "        dCl *= P_l1_p_l2_norm       * self.bias_velocity(k_l1_p_l2_norm,zi)     * self.bias_HI(k_l1_p_l2_norm,zi)\n",
    "        dCl_tot += dCl\n",
    "        print('Term 13', time.time() - t0)\n",
    "        # Term 14\n",
    "        dCl = -1.\n",
    "        dCl *= P_l2                 * self.bias_electron(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        dCl *= P_l_m_l1_p_l2_norm   * self.bias_velocity(k_l_m_l1_p_l2_norm,zi) * self.bias_velocity(k_l_m_l1_p_l2_norm,zi)\n",
    "        dCl *= P_l1_p_l2_norm       * self.bias_electron(k_l1_p_l2_norm,zi)     * self.bias_HI(k_l1_p_l2_norm,zi)\n",
    "        dCl_tot += dCl\n",
    "        print('Term 14', time.time() - t0)\n",
    "\n",
    "        # Delete redundant variables to save memory\n",
    "        del(P_l1_p_l2_norm, P_l_p_l2_norm, P_l2, P_l_m_l1_p_l2_norm)\n",
    "        # The beam functions\n",
    "        l_m_l1_norm = tc.sqrt( lsquare + l1square - 2*l_dot_l1 )\n",
    "        l_p_l2_norm = tc.sqrt( lsquare + l2square + 2*l_dot_l2 )\n",
    "        dCl_tot *= self.Beam_kSZ(l_m_l1_norm) * self.Beam_kSZ(l1) * self.Beam_HI(l_p_l2_norm) * self.Beam_HI(l2)\n",
    "        print('Beams ', time.time() - t0)\n",
    "        # The window functions and the metric determinant contribution \n",
    "        dCl_tot *= l1 * l2 * self.F_kSZ[zi]**2 * self.G_HI[zi]**2 * self.dchi_by_dz[zi]\n",
    "        print('Window functions', time.time() - t0)\n",
    "\n",
    "        dCl_res = tc.sum(dCl_tot) * t2_list[1] * (l_max - l_min) / (N_l - 1)\n",
    "\n",
    "        return dCl_res, dCl, dCl_tot\n",
    "\n",
    "    def dCl_timer_2d(self, zi, l, l1, l_min = 1, theta_option = True, l_max = 800, N_l = 1600, N_theta = 243):\n",
    "        \"\"\"Evaluare the integrand, dCl, as a function of z, l and l_1.\n",
    "\n",
    "        Here we sum over theta_1, l_2, and theta_2. To get the final C_l result, one has to integrate dCl over chi and l_1, for a given l.\n",
    "\n",
    "        Input\n",
    "        -----\n",
    "        `z` : float. \n",
    "            The redshift. \n",
    "\n",
    "        `l` : float. \n",
    "            The moment for C_l. Don't need to be an integer since we are in flat-sky approximation.\n",
    "\n",
    "        `l1` : float.\n",
    "            The norm of \\\\vec{l}_1.\n",
    "\n",
    "        \"\"\"\n",
    "        ##################################################\n",
    "        # Redefine the inputs as tc.tensors\n",
    "\n",
    "        t0 = time.time()\n",
    "        # z = tc.tensor([self.z_list[zindex]], dtype=tc.float64)\n",
    "        l = tc.tensor([l], dtype=tc.float64)\n",
    "        l1 = tc.tensor([l1], dtype=tc.float64)\n",
    "\n",
    "        # # Make the mesh grid for theta_1, |l_2|, and theta_2\n",
    "        # t1_list = tc.arange(N_theta, dtype=tc.float64) * tc.pi / N_theta\n",
    "        # t2_list = deepcopy(t1_list)\n",
    "        # l2_list = tc.linspace(l_min, l_max, N_l, dtype=tc.float64)\n",
    "        # l2, t1, t2 = tc.meshgrid(l2_list, t1_list, t2_list, indexing='ij')\n",
    "        \n",
    "        # Make the mesh grid for theta_1, |l_2|, and theta_2\n",
    "        t1 = tc.tensor([tc.pi / 3.], dtype=tc.float64)\n",
    "        if theta_option:\n",
    "            t2_list = tc.arange(N_theta, dtype=tc.float64) * 2 * tc.pi / N_theta + tc.pi / N_theta\n",
    "        else:\n",
    "            t2_list = tc.arange(N_theta, dtype=tc.float64) * 2 * tc.pi / N_theta\n",
    "        l2_list = tc.linspace(l_min, l_max, N_l, dtype=tc.float64) - (l_max - l_min) / (N_l - 1) / 2\n",
    "        l2, t2 = tc.meshgrid(l2_list, t2_list, indexing='ij')\n",
    "        print('Meshgrid finished ', time.time() - t0)\n",
    "\n",
    "        # Pre-define useful varibales and constants\n",
    "        chi = self.chi_of_z[zi]\n",
    "        lsquare = l**2\n",
    "        l1square = l1**2\n",
    "        l2square = l2**2\n",
    "\n",
    "        l_dot_l1 = Polar_dot(l, 0., l1, t1)\n",
    "        l_dot_l2 = Polar_dot(l, 0., l2, t2)\n",
    "        l1_dot_l2 = Polar_dot(l1, t1, l2, t2)\n",
    "\n",
    "        k_l1_p_l2_norm = tc.sqrt( l1square + l2square + 2*l1_dot_l2 ) / chi\n",
    "        k_l_p_l2_norm = tc.sqrt( lsquare + l2square + 2*l_dot_l2 ) / chi\n",
    "        k_l_m_l1_p_l2_norm = tc.sqrt( lsquare + l1square + l2square - 2*l_dot_l1 + 2*l_dot_l2 - 2*l1_dot_l2 ) / chi\n",
    "        k_l2 = l2 / chi\n",
    "\n",
    "        print('k norms have been evaluated ', time.time() - t0)\n",
    "        # Delete redundant variables to save memory\n",
    "        del(l1_dot_l2)\n",
    "\n",
    "        theta_l_p_l2 = Evaluate_angle(2, l, tc.tensor([0.]), l2, t2)\n",
    "        theta_l1_p_l2 = Evaluate_angle(2, l, tc.tensor([0.]), l2, t2)\n",
    "        theta_l_m_l1_p_l2 = Evaluate_angle(3, l, tc.tensor([0.]), -l1, t1, l2, t2)\n",
    "        print('Angles have been evaluated ', time.time() - t0)\n",
    "\n",
    "        # Pre-calculate the matter power spectrum\n",
    "        P_l1_p_l2_norm = self.Power_matter_1d(k_l1_p_l2_norm, zi)\n",
    "        P_l_p_l2_norm = self.Power_matter_1d(k_l_p_l2_norm, zi)\n",
    "        P_l2 = self.Power_matter_1d(k_l2, zi)\n",
    "        P_l_m_l1_p_l2_norm = self.Power_matter_1d(k_l_m_l1_p_l2_norm, zi)\n",
    "        print('Powers have been evaluated ', time.time() - t0)\n",
    "       \n",
    "\n",
    "        ##################################################\n",
    "        # Evaluate the integrand\n",
    "        # Initialization\n",
    "        dCl_tot = tc.zeros_like(t2)\n",
    "\n",
    "        # Contribution originate from each term in Wick Theorem\n",
    "        # Term 5 and Term 6\n",
    "        dCl0 = - tc.cos(theta_l1_p_l2 - t2)\n",
    "        dCl1 = P_l1_p_l2_norm * self.bias_electron(k_l1_p_l2_norm,zi)**2 + P_l_m_l1_p_l2_norm * self.bias_electron(k_l_m_l1_p_l2_norm,zi)**2\n",
    "        dCl2 = P_l_p_l2_norm        * self.bias_velocity(k_l1_p_l2_norm,zi)     * self.bias_HI(k_l1_p_l2_norm,zi)\n",
    "        dCl3 = P_l2                 * self.bias_velocity(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        dCl_tot = dCl_tot + dCl1 * dCl2 * dCl3 * dCl0\n",
    "        print('Term 5 and 6', time.time() - t0)\n",
    "        # # Term 8 \n",
    "        # dCl = tc.cos(theta_l_p_l2 - theta_l1_p_l2)\n",
    "        # dCl *= P_l_m_l1_p_l2_norm   * self.bias_electron(k_l_m_l1_p_l2_norm,zi) * self.bias_velocity(k_l_m_l1_p_l2_norm,zi)\n",
    "        # dCl *= P_l_p_l2_norm        * self.bias_electron(k_l_p_l2_norm,zi)      * self.bias_HI(k_l_p_l2_norm,zi)\n",
    "        # dCl *= P_l2                 * self.bias_velocity(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        # dCl_tot += dCl\n",
    "        # print('Term 8', time.time() - t0)\n",
    "        # # Term 9\n",
    "        # dCl = tc.cos(theta_l_m_l1_p_l2 - t2)\n",
    "        # dCl *= P_l1_p_l2_norm       * self.bias_electron(k_l1_p_l2_norm,zi)     * self.bias_velocity(k_l1_p_l2_norm,zi)\n",
    "        # dCl *= P_l2                 * self.bias_electron(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        # dCl *= P_l_p_l2_norm        * self.bias_velocity(k_l_p_l2_norm,zi)      * self.bias_HI(k_l_p_l2_norm,zi)\n",
    "        # dCl_tot += dCl\n",
    "        # print('Term 9', time.time() - t0)\n",
    "        # # Term 10\n",
    "        # dCl = tc.cos(theta_l1_p_l2 - t2)\n",
    "        # dCl *= P_l_p_l2_norm        * self.bias_electron(k_l_p_l2_norm,zi)      * self.bias_HI(k_l_p_l2_norm,zi)\n",
    "        # dCl *= P_l1_p_l2_norm       * self.bias_electron(k_l1_p_l2_norm,zi)     * self.bias_velocity(k_l1_p_l2_norm,zi)\n",
    "        # dCl *= P_l2                 * self.bias_velocity(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        # dCl_tot += dCl\n",
    "        # print('Term 10', time.time() - t0)\n",
    "        # # Term 11\n",
    "        # dCl = -1.\n",
    "        # dCl *= P_l_p_l2_norm        * self.bias_electron(k_l_p_l2_norm,zi)      * self.bias_HI(k_l_p_l2_norm,zi)\n",
    "        # dCl *= P_l1_p_l2_norm       * self.bias_velocity(k_l1_p_l2_norm,zi)     * self.bias_velocity(k_l1_p_l2_norm,zi)\n",
    "        # dCl *= P_l2                 * self.bias_electron(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        # dCl_tot += dCl\n",
    "        # print('Term 11', time.time() - t0)\n",
    "        # # Term 13\n",
    "        # dCl = tc.cos(theta_l_m_l1_p_l2 - theta_l_p_l2)\n",
    "        # dCl *= P_l2                 * self.bias_electron(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        # dCl *= P_l_m_l1_p_l2_norm   * self.bias_electron(k_l_m_l1_p_l2_norm,zi) * self.bias_velocity(k_l_m_l1_p_l2_norm,zi)\n",
    "        # dCl *= P_l1_p_l2_norm       * self.bias_velocity(k_l1_p_l2_norm,zi)     * self.bias_HI(k_l1_p_l2_norm,zi)\n",
    "        # dCl_tot += dCl\n",
    "        # print('Term 13', time.time() - t0)\n",
    "        # # Term 14\n",
    "        # dCl = -1.\n",
    "        # dCl *= P_l2                 * self.bias_electron(k_l2,zi)               * self.bias_HI(k_l2,zi)\n",
    "        # dCl *= P_l_m_l1_p_l2_norm   * self.bias_velocity(k_l_m_l1_p_l2_norm,zi) * self.bias_velocity(k_l_m_l1_p_l2_norm,zi)\n",
    "        # dCl *= P_l1_p_l2_norm       * self.bias_electron(k_l1_p_l2_norm,zi)     * self.bias_HI(k_l1_p_l2_norm,zi)\n",
    "        # dCl_tot += dCl\n",
    "        # print('Term 14', time.time() - t0)\n",
    "\n",
    "        print(tc.sum(l1 * l2 * dCl_tot)  * (l_max - l_min) / (N_l - 1) * 2 * tc.pi / N_theta)\n",
    "\n",
    "        # Delete redundant variables to save memory\n",
    "        del(P_l1_p_l2_norm, P_l_p_l2_norm, P_l2, P_l_m_l1_p_l2_norm)\n",
    "        # The beam functions\n",
    "        l_m_l1_norm = tc.sqrt( lsquare + l1square - 2*l_dot_l1 )\n",
    "        l_p_l2_norm = tc.sqrt( lsquare + l2square + 2*l_dot_l2 )\n",
    "        dCl_tot *= self.Beam_kSZ(l_m_l1_norm) * self.Beam_kSZ(l1) * self.Beam_HI(l_p_l2_norm) * self.Beam_HI(l2)\n",
    "        print('Beams ', time.time() - t0)\n",
    "        # The window functions and the metric determinant contribution \n",
    "        dCl_tot *= l1 * l2 * self.F_kSZ[zi]**2 * self.G_HI[zi]**2 * self.dchi_by_dz[zi]\n",
    "        print('Window functions', time.time() - t0)\n",
    "\n",
    "        dCl_res = tc.sum(dCl_tot)  * (l_max - l_min) / (N_l - 1) * 2 * tc.pi / N_theta\n",
    "\n",
    "        return l2, t2, dCl_res, dCl_tot, dCl1, dCl2, dCl3, dCl0\n",
    "\n",
    "\n",
    "\n",
    "def Polar_dot(lx, thetax, ly, thetay):\n",
    "    return lx * ly * np.cos(thetax - thetay)\n",
    "\n",
    "def Evaluate_angle(N_vec, *vectors):\n",
    "\n",
    "    if 2*N_vec != len(vectors):\n",
    "        print('The input N_vec does not match the number of input vectors')\n",
    "        raise\n",
    "    else:\n",
    "        # We need to do some adjustment on vectors to match the broadcast rule\n",
    "        # In order to keep vectors unchanged, make a copy of them for calculation\n",
    "        vec = deepcopy(vectors)\n",
    "\n",
    "        l_x = 0.\n",
    "        l_y = 0.\n",
    "        for i in range(N_vec):\n",
    "            l_x = l_x + vec[2*i] * tc.cos(vec[2*i+1])\n",
    "            l_y = l_y + vec[2*i] * tc.sin(vec[2*i+1])\n",
    "        \n",
    "        return tc.atan2(l_y, l_x)\n",
    "    \n",
    "def torch_interp1d(x, y, x_query):\n",
    "\n",
    "    indices = tc.searchsorted(x, x_query) - 1\n",
    "    indices = tc.clamp(indices, 0, len(x) - 2)\n",
    "\n",
    "    x0, x1 = x[indices], x[indices + 1]\n",
    "    y0, y1 = y[indices], y[indices + 1]\n",
    "    \n",
    "    slope = (y1 - y0) / (x1 - x0)\n",
    "    y_query = y0 + slope * (x_query - x0)\n",
    "    \n",
    "    return y_query\n",
    "\n",
    "def torch_interp2d(x, y, z, x_new, y_new, mode='bilinear'):\n",
    "    '''\n",
    "    Interpolates 2D data over a grid using PyTorch, mimicking `scipy.interpolate.interp2d`.\n",
    "    \n",
    "    Parameters:\n",
    "        x (torch.Tensor): 1D tensor of x coordinates (size: N).\n",
    "        y (torch.Tensor): 1D tensor of y coordinates (size: M).\n",
    "        z (torch.Tensor): 2D tensor of shape (M, N) representing the grid values.\n",
    "        x_new (torch.Tensor): 1D tensor of new x coordinates for interpolation (size: N').\n",
    "        y_new (torch.Tensor): 1D tensor of new y coordinates for interpolation (size: M').\n",
    "        mode (str): Interpolation mode ('bilinear', 'nearest'). Defaults to 'bilinear'.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Interpolated values at new (x_new, y_new) grid points.\n",
    "    '''\n",
    "    \n",
    "    # Ensure the input tensors are of the correct shape\n",
    "\n",
    "    z = z.unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions (1, 1, M, N)\n",
    "    \n",
    "    # Create the meshgrid for new points (x_new, y_new)\n",
    "    x_new_grid, y_new_grid = tc.meshgrid(x_new, y_new, indexing='ij')\n",
    "    \n",
    "    # Normalize new grid coordinates to range [-1, 1] (for grid_sample)\n",
    "    x_min, x_max = x.min(), x.max()\n",
    "    y_min, y_max = y.min(), y.max()\n",
    "    \n",
    "    x_new_norm = 2 * (x_new_grid - x_min) / (x_max - x_min) - 1\n",
    "    y_new_norm = 2 * (y_new_grid - y_min) / (y_max - y_min) - 1\n",
    "    \n",
    "    # Stack and reshape the new coordinates into (1, H', W', 2) for grid_sample\n",
    "    grid = tc.stack((x_new_norm, y_new_norm), dim=-1).unsqueeze(0)\n",
    "    \n",
    "    # Perform the interpolation using grid_sample\n",
    "    interpolated = tc.nn.functional.grid_sample(z, grid, mode=mode, align_corners=True)\n",
    "    \n",
    "    # Remove the batch and channel dimensions and return the result\n",
    "    return interpolated.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: redshifts have been re-sorted (earliest first)\n"
     ]
    }
   ],
   "source": [
    "testclass = Cl_kSZ2_HI2(np.linspace(0.3, 0.6, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meshgrid finished  0.0\n",
      "k norms have been evaluated  0.012997865676879883\n",
      "Angles have been evaluated  0.018900632858276367\n",
      "Powers have been evaluated  0.03425025939941406\n",
      "Term 5 and 6 0.04226112365722656\n",
      "tensor(-117712.7615)\n",
      "Beams  0.04226112365722656\n",
      "Window functions 0.04226112365722656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.6846e-14)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2, t2, dClres, dCl_tot, dCl1, dCl2, dCl3, dCl0 = testclass.dCl_timer_2d(0, 200, 200, theta_option=True)#, l_max=800, N_l=1600, N_theta=243)\n",
    "dClres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax3 = plt.axes(projection='3d')\n",
    "\n",
    "# xi = 150; xe = 200; yi = 38; ye = 44\n",
    "# xi = 150; xe = 250; yi = 25; ye = 38\n",
    "# xi = 150; xe = 250; yi = 48; ye = 60\n",
    "# xi = 100; xe = 300; yi = 115; ye = 130\n",
    "# xi = 0; xe = 800; yi = 0; ye = -1\n",
    "xi = 350; xe = 450; yi = 152; ye = 170\n",
    "\n",
    "# ax3.plot_surface(l2[xi:xe,yi:ye], t2[xi:xe,yi:ye], dCl1[xi:xe,yi:ye],cmap='rainbow')\n",
    "# ax3.plot_surface(tc.log10(l2[xi:xe,yi:ye]), t2[xi:xe,yi:ye], dCl1[xi:xe,yi:ye],cmap='rainbow')\n",
    "\n",
    "ax3.plot_surface(l2[xi:xe,yi:ye], t2[xi:xe,yi:ye], dCl1[xi:xe,yi:ye],cmap='rainbow')\n",
    "# ax3.plot_surface(tc.log10(l2[xi:xe,yi:ye]), t2[xi:xe,yi:ye], dCl_tot[xi:xe,yi:ye],cmap='rainbow')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1600, 243, 243])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(707.1861)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dClres = testclass.dCl(0.4, 200, 200, l_max=800, N_l=1600, N_theta=243)\n",
    "dClres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = tc.arange(10)\n",
    "test2 = tc.arange(13)\n",
    "test3 = tc.arange(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(test1, test2, test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4943)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2, t2, dClres, dCl_tot, dCl_terms = testclass.dCl(0.4, 200, 200, l_max=800, N_l=1600, N_theta=729)\n",
    "dClres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax3 = plt.axes(projection='3d')\n",
    "\n",
    "# xi = 150; xe = 200; yi = 38; ye = 44\n",
    "# xi = 150; xe = 250; yi = 25; ye = 38\n",
    "# xi = 150; xe = 250; yi = 48; ye = 60\n",
    "# xi = 100; xe = 300; yi = 115; ye = 130\n",
    "xi = 200; xe = 250; yi = 0; ye = -1\n",
    "# xi = 150; xe = 250; yi = 50; ye = 70\n",
    "\n",
    "# ax3.plot_surface(l2[xi:xe,yi:ye], t2[xi:xe,yi:ye], dCl1[xi:xe,yi:ye],cmap='rainbow')\n",
    "# ax3.plot_surface(tc.log10(l2[xi:xe,yi:ye]), t2[xi:xe,yi:ye], dCl1[xi:xe,yi:ye],cmap='rainbow')\n",
    "\n",
    "ax3.plot_surface(l2[xi:xe,yi:ye], t2[xi:xe,yi:ye], dCl_tot[xi:xe,yi:ye],cmap='rainbow')\n",
    "# ax3.plot_surface(tc.log10(l2[xi:xe,yi:ye]), t2[xi:xe,yi:ye], dCl_tot[xi:xe,yi:ye],cmap='rainbow')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1948)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dClres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2574)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dClres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = testclass.Cross_Power(0.4, tc.linspace(0,100,300), b1='v', b2='v')\n",
    "\n",
    "mesh = np.isnan(np.array(test1))\n",
    "mesh.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2, t2, dCl_tot, dCl0, dCl1, dCl2, dCl3, dCl_Beam, dCl_FG, l1_p_l2_norm, l_p_l2_norm, l_m_l1_p_l2_norm = testclass.dCl(0.4, 200, 200, N_theta=81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax3 = plt.axes(projection='3d')\n",
    "\n",
    "# xi = 150; xe = 250; yi = 38; ye = 44\n",
    "# xi = 100; xe = 300; yi = 115; ye = 130\n",
    "# xi = 0; xe = -1; yi = 0; ye = -1\n",
    "xi = 150; xe = 250; yi = 50; ye = 70\n",
    "\n",
    "# ax3.plot_surface(tc.log10(l2[xi:xe,yi:ye]), t2[xi:xe,yi:ye], dCl0[xi:xe,yi:ye],cmap='rainbow')\n",
    "# ax3.plot_surface(tc.log10(l2[xi:xe,yi:ye]), t2[xi:xe,yi:ye], dCl1[xi:xe,yi:ye],cmap='rainbow')\n",
    "# ax3.plot_surface(tc.log10(l2[xi:xe,yi:ye]), t2[xi:xe,yi:ye], dCl2[xi:xe,yi:ye],cmap='rainbow')\n",
    "# ax3.plot_surface(tc.log10(l2[xi:xe,yi:ye]), t2[xi:xe,yi:ye], dCl3[xi:xe,yi:ye],cmap='rainbow')\n",
    "# ax3.plot_surface(tc.log10(l2[xi:xe,yi:ye]), t2[xi:xe,yi:ye], dCl_Beam[xi:xe,yi:ye],cmap='rainbow')\n",
    "\n",
    "# ax3.plot_surface(l2[xi:xe,yi:ye], t2[xi:xe,yi:ye], dCl_tot[xi:xe,yi:ye],cmap='rainbow')\n",
    "ax3.plot_surface(tc.log10(l2[xi:xe,yi:ye]), t2[xi:xe,yi:ye], dCl_tot[xi:xe,yi:ye],cmap='rainbow')\n",
    "# ax3.plot_surface(tc.log10(l2[xi:xe,yi:ye]), t2[xi:xe,yi:ye], tc.log10(tc.abs(dCl_tot[xi:xe,yi:ye])),cmap='rainbow')\n",
    "\n",
    "# ax3.plot_surface(tc.log10(l2[xi:xe,yi:ye]), t2[xi:xe,yi:ye], l1_p_l2_norm[xi:xe,yi:ye],cmap='rainbow')\n",
    "# ax3.plot_surface(tc.log10(l2[xi:xe,yi:ye]), t2[xi:xe,yi:ye], l_p_l2_norm[xi:xe,yi:ye],cmap='rainbow')\n",
    "# ax3.plot_surface(tc.log10(l2[xi:xe,yi:ye]), t2[xi:xe,yi:ye], l_m_l1_p_l2_norm[xi:xe,yi:ye],cmap='rainbow')\n",
    "# ax3.plot_surface(l2[xi:xe,yi:ye], t2[xi:xe,yi:ye], l_m_l1_p_l2_norm[xi:xe,yi:ye],cmap='rainbow')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1168108.4772, 1168108.4772, 1168108.4772,  ..., 1168108.4772,\n",
       "         1168108.4772, 1168108.4772],\n",
       "        [1168108.4772, 1168108.4772, 1168108.4772,  ..., 1168108.4772,\n",
       "         1168108.4772, 1168108.4772],\n",
       "        [1168108.4772, 1168108.4772, 1168108.4772,  ..., 1168108.4772,\n",
       "         1168108.4772, 1168108.4772],\n",
       "        ...,\n",
       "        [1168108.4772, 1168108.4772, 1168108.4772,  ..., 1168108.4772,\n",
       "         1168108.4772, 1168108.4772],\n",
       "        [1168108.4772, 1168108.4772, 1168108.4772,  ..., 1168108.4772,\n",
       "         1168108.4772, 1168108.4772],\n",
       "        [1168108.4772, 1168108.4772, 1168108.4772,  ..., 1168108.4772,\n",
       "         1168108.4772, 1168108.4772]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dCl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tc.where(l_p_l2_norm <= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1200.)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_p_l2_norm.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0322e+01, 9.0000e+00, 1.0322e+01, 1.3533e+01],\n",
       "        [9.4695e+00, 8.0000e+00, 9.4695e+00, 1.2910e+01],\n",
       "        [8.6490e+00, 7.0000e+00, 8.6490e+00, 1.2337e+01],\n",
       "        [7.8701e+00, 6.0000e+00, 7.8701e+00, 1.1821e+01],\n",
       "        [7.1465e+00, 5.0000e+00, 7.1465e+00, 1.1370e+01],\n",
       "        [6.4967e+00, 4.0000e+00, 6.4967e+00, 1.0991e+01],\n",
       "        [5.9448e+00, 3.0000e+00, 5.9448e+00, 1.0693e+01],\n",
       "        [5.5203e+00, 2.0000e+00, 5.5203e+00, 1.0482e+01],\n",
       "        [5.2543e+00, 1.0000e+00, 5.2543e+00, 1.0364e+01],\n",
       "        [5.1712e+00, 2.6974e-06, 5.1712e+00, 1.0342e+01],\n",
       "        [5.2797e+00, 1.0000e+00, 5.2797e+00, 1.0415e+01],\n",
       "        [5.5685e+00, 2.0000e+00, 5.5685e+00, 1.0584e+01],\n",
       "        [6.0119e+00, 3.0000e+00, 6.0119e+00, 1.0842e+01],\n",
       "        [6.5785e+00, 4.0000e+00, 6.5785e+00, 1.1184e+01],\n",
       "        [7.2395e+00, 5.0000e+00, 7.2395e+00, 1.1603e+01],\n",
       "        [7.9714e+00, 6.0000e+00, 7.9714e+00, 1.2089e+01],\n",
       "        [8.7566e+00, 7.0000e+00, 8.7566e+00, 1.2637e+01],\n",
       "        [9.5818e+00, 8.0000e+00, 9.5818e+00, 1.3237e+01],\n",
       "        [1.0438e+01, 9.0000e+00, 1.0438e+01, 1.3884e+01],\n",
       "        [1.1317e+01, 1.0000e+01, 1.1317e+01, 1.4570e+01]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_m_l1_p_l2_norm[190:210, 80:84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = testclass.results\n",
    "background = testclass.BGEvolution\n",
    "\n",
    "kh_list = testclass.kh_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "testv = background.get_time_evolution(q=kh_list, eta=testclass.chi(0.45), vars='v_newtonian_baryon').flatten()\n",
    "testm = background.get_time_evolution(q=kh_list, eta=testclass.chi(0.45), vars='delta_baryon').flatten()\n",
    "testbias = (testclass.Growth_Rate_of_z(background, itp_order='linear'))(0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kh_list, testv)\n",
    "plt.plot(kh_list, testm)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testkh, testz, testPv = results.get_matter_power_spectrum(npoints=500, var1='v_newtonian_baryon', var2='v_newtonian_baryon')\n",
    "testkh, testz, testPb = results.get_matter_power_spectrum(npoints=500, var1='delta_baryon', var2='delta_baryon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "zindex = 3\n",
    "\n",
    "plt.plot(kh_list, testPv[zindex])\n",
    "plt.plot(kh_list, testPb[zindex])\n",
    "plt.plot(kh_list, testPb[zindex] * testclass.f_of_z(testz[zindex])**2, '--')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kh_list, testPv[zindex] / kh_list**2)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: redshifts have been re-sorted (earliest first)\n"
     ]
    }
   ],
   "source": [
    "testclass = Cl_kSZ2_HI2(np.linspace(0.3, 0.6, 10))\n",
    "z0 = 0.4; chi0 = testclass.chi(z0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "dCl2_linear, l2_linear, t2_linear, l_p_l2_norm_linear, l1_p_l2_norm_linear, l_m_l1_p_l2_norm_linear = testclass.test(z0, 200, 200, method='linear', l_max=1000, N_l=1000, N_theta=18)\n",
    "dCl2_log, l2_log, t2_log, l_p_l2_norm_log, l1_p_l2_norm_log, l_m_l1_p_l2_norm_log = testclass.test(z0, 200, 200, method='log', l_max=1000, N_l=1000, N_theta=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([110119.8540, 109650.8207, 109186.4085, 108726.5493, 108271.1765,\n",
       "        107820.2249, 107373.6302, 106931.3298, 106493.2619, 106059.3660])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dCl2_linear[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([110119.8540, 110116.5835, 110113.2905, 110109.9749, 110106.6365,\n",
       "        110103.2752, 110099.8908, 110096.4832, 110093.0521, 110089.5976])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dCl2_log[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([201., 202., 203., 204., 205., 206., 207., 208., 209., 210.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_p_l2_norm_linear[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([201.0000, 201.0069, 201.0139, 201.0210, 201.0280, 201.0352, 201.0424,\n",
       "        201.0496, 201.0569, 201.0642])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_p_l2_norm_log[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j8/mz7l4_197pn37cbb5wq5lgw40000gn/T/ipykernel_3662/1927064770.py:304: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kh_new = tc.tensor(kh.flatten())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 18]), torch.Size([1000, 18]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testk1 = l_p_l2_norm_linear / chi0\n",
    "testk2 = l_p_l2_norm_log / chi0\n",
    "P1, Pnew1, k1, bv1, bHI1 = testclass.Cross_Power_test(z0, testk1, 'v', 'HI')\n",
    "P2, Pnew2, k2, bv2, bHI2 = testclass.Cross_Power_test(z0, testk2, 'v', 'HI')\n",
    "\n",
    "testk1.shape, testk2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1258, 0.1257],\n",
       "         [0.1264, 0.1263],\n",
       "         [0.1270, 0.1269],\n",
       "         [0.1276, 0.1275],\n",
       "         [0.1283, 0.1281],\n",
       "         [0.1289, 0.1287],\n",
       "         [0.1295, 0.1293],\n",
       "         [0.1302, 0.1299],\n",
       "         [0.1308, 0.1305],\n",
       "         [0.1314, 0.1310]]),\n",
       " tensor([[0.1258, 0.1257],\n",
       "         [0.1258, 0.1257],\n",
       "         [0.1258, 0.1257],\n",
       "         [0.1258, 0.1257],\n",
       "         [0.1258, 0.1258],\n",
       "         [0.1258, 0.1258],\n",
       "         [0.1258, 0.1258],\n",
       "         [0.1258, 0.1258],\n",
       "         [0.1258, 0.1258],\n",
       "         [0.1258, 0.1258]]))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testk1[:10, :2], testk2[:10, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1258, 0.1257, 0.1256,  ..., 0.6968, 0.7261, 0.7446])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testk1.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1258, 0.1257, 0.1256, 0.1255, 0.1253, 0.1250, 0.1248, 0.1247, 0.1246,\n",
       "         0.1245]),\n",
       " tensor([0.1258, 0.1257, 0.1256, 0.1255, 0.1253, 0.1250, 0.1248, 0.1247, 0.1246,\n",
       "         0.1245]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1[:10], k2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([319.7195, 319.7062, 319.6678, 319.6089, 319.5365, 319.4594, 319.3868,\n",
       "        319.3275, 319.2888, 319.2753])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testres1 = testclass.Pm_interpolation(k1[:-10], tc.tensor([z0]))\n",
    "# testres2 = testclass.Pm(k2,z0)\n",
    "testres1[:10]#, testres2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([319.7195, 319.7062, 319.6678, 319.6089, 319.5365, 319.4594, 319.3868,\n",
       "         319.3275, 319.2888, 319.2753]),\n",
       " tensor([319.7195, 319.7062, 319.6678, 319.6089, 319.5365, 319.4594, 319.3868,\n",
       "         319.3275, 319.2888, 319.2753]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1[:10], P2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([319.7195, 319.9416, 320.1637, 320.3858, 320.6079, 320.8300, 321.0521,\n",
       "         321.2741, 321.4962, 321.7183]),\n",
       " tensor([319.7195, 319.7211, 319.7226, 319.7242, 319.7258, 319.7273, 319.7289,\n",
       "         319.7305, 319.7322, 319.7338]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pnew1[:10, 0], Pnew2[:10, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([344.4264, 342.7213, 341.0331, 339.3613, 337.7059, 336.0666, 334.4431,\n",
       "         332.8352, 331.2426, 329.6653]),\n",
       " tensor([344.4264, 344.4145, 344.4026, 344.3905, 344.3784, 344.3662, 344.3539,\n",
       "         344.3415, 344.3290, 344.3164]))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv1[:10,0], bv2[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1258, 0.1257, 0.1256,  ..., 0.1255, 0.1256, 0.1257],\n",
       "        [0.1258, 0.1257, 0.1256,  ..., 0.1255, 0.1256, 0.1257],\n",
       "        [0.1258, 0.1257, 0.1256,  ..., 0.1255, 0.1256, 0.1257],\n",
       "        ...,\n",
       "        [0.7423, 0.7360, 0.7175,  ..., 0.6883, 0.7175, 0.7360],\n",
       "        [0.7466, 0.7403, 0.7218,  ..., 0.6925, 0.7218, 0.7403],\n",
       "        [0.7509, 0.7446, 0.7261,  ..., 0.6968, 0.7261, 0.7446]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_p_l2_norm_log / chi0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuwen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
